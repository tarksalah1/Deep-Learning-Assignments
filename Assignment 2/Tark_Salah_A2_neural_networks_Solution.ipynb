{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d2fed8c8-3b58-464a-b89d-df85d934f740",
      "metadata": {
        "id": "d2fed8c8-3b58-464a-b89d-df85d934f740"
      },
      "source": [
        "---\n",
        "# Cairo University Faculty of Engineering\n",
        "## Deep Learning \n",
        "## Assignment 2\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f09594d-0c42-4205-a0af-77097e41f555",
      "metadata": {
        "id": "9f09594d-0c42-4205-a0af-77097e41f555"
      },
      "source": [
        "Please write your full name here\n",
        "- **Name** : \"tark salah desokey\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib==3.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "sTc0sCXcXpnX",
        "outputId": "8300172a-d824-44a2-a432-01d583514ff7"
      },
      "id": "sTc0sCXcXpnX",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting matplotlib==3.0\n",
            "  Downloading matplotlib-3.0.0-cp37-cp37m-manylinux1_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.0) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.0) (1.15.0)\n",
            "Installing collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires matplotlib!=3.0.0,>=2.0.2, but you have matplotlib 3.0.0 which is incompatible.\n",
            "scikit-image 0.18.3 requires matplotlib!=3.0.0,>=2.0.0, but you have matplotlib 3.0.0 which is incompatible.\n",
            "plotnine 0.8.0 requires matplotlib>=3.1.1, but you have matplotlib 3.0.0 which is incompatible.\n",
            "mizani 0.7.3 requires matplotlib>=3.1.1, but you have matplotlib 3.0.0 which is incompatible.\u001b[0m\n",
            "Successfully installed matplotlib-3.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install d2l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HVh6wtXEZYwm",
        "outputId": "a2964ee0-4af7-470f-bfe1-726bf40f5e8b"
      },
      "id": "HVh6wtXEZYwm",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting d2l\n",
            "  Downloading d2l-0.17.5-py3-none-any.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 574 kB/s \n",
            "\u001b[?25hCollecting jupyter==1.0.0\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Collecting numpy==1.21.5\n",
            "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 27.3 MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.5.1\n",
            "  Downloading matplotlib-3.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 46.0 MB/s \n",
            "\u001b[?25hCollecting pandas==1.2.4\n",
            "  Downloading pandas-1.2.4-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting requests==2.25.1\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.3.4)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (6.1.0)\n",
            "Collecting qtconsole\n",
            "  Downloading qtconsole-5.3.2-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 74.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.5.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.6.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (7.7.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (2.8.2)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 55.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (21.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.1->d2l) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.4->d2l) (2022.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (2022.9.24)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.5.1->d2l) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.1->d2l) (1.15.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (7.9.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (4.8.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 49.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (4.4.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (2.0.10)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.2.5)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.6.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.0.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.13.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (5.7.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (23.2.1)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (4.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (2.11.3)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter==1.0.0->d2l) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter==1.0.0->d2l) (2.0.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.0.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter==1.0.0->d2l) (2.16.2)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter==1.0.0->d2l) (4.13.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter==1.0.0->d2l) (4.3.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->notebook->jupyter==1.0.0->d2l) (3.10.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter==1.0.0->d2l) (5.10.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter==1.0.0->d2l) (22.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter==1.0.0->d2l) (0.18.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l) (0.5.1)\n",
            "Collecting qtpy>=2.0.1\n",
            "  Downloading QtPy-2.2.1-py3-none-any.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 718 kB/s \n",
            "\u001b[?25hInstalling collected packages: jedi, qtpy, qtconsole, numpy, fonttools, requests, pandas, matplotlib, jupyter, d2l\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.0.0\n",
            "    Uninstalling matplotlib-3.0.0:\n",
            "      Successfully uninstalled matplotlib-3.0.0\n",
            "Successfully installed d2l-0.17.5 fonttools-4.38.0 jedi-0.18.1 jupyter-1.0.0 matplotlib-3.5.1 numpy-1.21.5 pandas-1.2.4 qtconsole-5.3.2 qtpy-2.2.1 requests-2.25.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib_inline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__QcJR3KTQIm",
        "outputId": "3ccad60a-194d-4284-e42a-e720fd2ebd2f"
      },
      "id": "__QcJR3KTQIm",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting matplotlib_inline\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.7/dist-packages (from matplotlib_inline) (5.1.1)\n",
            "Installing collected packages: matplotlib-inline\n",
            "Successfully installed matplotlib-inline-0.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "02dc8d6e-7d9a-48c0-a84d-fdd3c63c9c78",
      "metadata": {
        "id": "02dc8d6e-7d9a-48c0-a84d-fdd3c63c9c78"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from d2l import tensorflow as d2l\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "from sklearn.datasets import make_blobs  #To generate artificial data\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6055f2a1-24c2-46eb-92a8-b9f387f3dcc2",
      "metadata": {
        "id": "6055f2a1-24c2-46eb-92a8-b9f387f3dcc2",
        "tags": []
      },
      "source": [
        "# Part 1 Computational Graphs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ea98a23-c5be-4a87-8a53-588fbdcadf1e",
      "metadata": {
        "id": "5ea98a23-c5be-4a87-8a53-588fbdcadf1e"
      },
      "source": [
        "## Example\n",
        "Suppose that we have a function of the form: $f(x,y) = \\sigma(x) + (x-y)^2$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ead972fc-bc4a-4f70-bd22-473a84326027",
      "metadata": {
        "id": "ead972fc-bc4a-4f70-bd22-473a84326027"
      },
      "source": [
        "**SHOW YOUR WORK**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d072290-86f5-4f6c-8e64-0c2b6ee79114",
      "metadata": {
        "id": "4d072290-86f5-4f6c-8e64-0c2b6ee79114"
      },
      "source": [
        "0. **Draw its computational graph with a minimum of 4 operations inside it. Name your intermediate variables and upload a picture of your graph**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dc590ee-33e8-458a-ba81-fd2e6ca01b79",
      "metadata": {
        "id": "1dc590ee-33e8-458a-ba81-fd2e6ca01b79"
      },
      "source": [
        "- Your Answer:\n",
        "    - ![Question1](https://user-images.githubusercontent.com/61361818/198404593-0c4ccf16-2010-40f6-ad66-14a0c29cc7db.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e95e6d93-ec11-40d6-a639-40fad6e1ad3c",
      "metadata": {
        "id": "e95e6d93-ec11-40d6-a639-40fad6e1ad3c"
      },
      "source": [
        "1. **Compute the forward path for this function. Use intermediate variables you identified in your graph**\n",
        "\n",
        "- f --> final output\n",
        "- Upload a a picture of your graph"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f9df23d-f8f6-4408-a2cf-943987324775",
      "metadata": {
        "id": "0f9df23d-f8f6-4408-a2cf-943987324775"
      },
      "source": [
        "- Your Answer:\n",
        "    - ![Question2](https://user-images.githubusercontent.com/61361818/198404686-075ee738-83d5-4f5f-8208-43485b23c82b.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "902480a7-16e1-415e-bdea-24fe845774fe",
      "metadata": {
        "id": "902480a7-16e1-415e-bdea-24fe845774fe"
      },
      "source": [
        "\n",
        "2. **Compute the backward path for this function to get:**\n",
        "$$\n",
        "\\nabla f(x,y) = [ \\frac{\\partial f}{\\partial y}, \\frac{\\partial f}{\\partial x} ]\n",
        "$$\n",
        "\n",
        "- Upload a a picture of your graph\n",
        "- **Use intermediate variables**\n",
        "- **Write df/dy and df/dx**\n",
        "- *Hint: Gradients add up at forks. This follows the multivariable chain rule in Calculus, which states that if a variable branches out to different parts, then the gradients that flow back to it will add.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c83b8b27-0cb2-4c2e-9eea-351fc216d952",
      "metadata": {
        "id": "c83b8b27-0cb2-4c2e-9eea-351fc216d952"
      },
      "source": [
        "- Your Answer:\n",
        "    - ![Question3](https://user-images.githubusercontent.com/61361818/198404747-1e9abfc1-b373-481f-8d3f-24741c5c205c.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f383a40-2b6d-4bb3-bb45-4b6602896480",
      "metadata": {
        "tags": [],
        "id": "4f383a40-2b6d-4bb3-bb45-4b6602896480"
      },
      "source": [
        "# Part 2: Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ddb4513-a883-475c-acb4-7daf8a1434a7",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "origin_pos": 0,
        "tags": [],
        "id": "0ddb4513-a883-475c-acb4-7daf8a1434a7"
      },
      "source": [
        "In this part, (**we will implement the entire linear regression method from scratch,\n",
        "including the data pipeline, the model,\n",
        "the loss function, and the minibatch stochastic gradient descent optimizer.**)\n",
        "You will rely only on tensors and auto differentiation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9885bf7b-0575-456d-a16c-997636bb6b3b",
      "metadata": {
        "id": "9885bf7b-0575-456d-a16c-997636bb6b3b"
      },
      "source": [
        "we will use $n$ to denote\n",
        "the number of examples in our dataset.\n",
        "We index the data examples by $i$, denoting each input\n",
        "as $\\mathbf{x}^{(i)} = [x_1^{(i)}, x_2^{(i)}]^\\top$\n",
        "and the corresponding label as $y^{(i)}$.\n",
        "\n",
        "\n",
        "**Linear Model**\n",
        "\n",
        "When our inputs consist of $d$ features,\n",
        "we express our prediction $\\hat{y}$ (in general the \"hat\" symbol denotes estimates) as\n",
        "\n",
        "$$\\hat{y} = w_1  x_1 + ... + w_d  x_d + b.$$\n",
        "\n",
        "\n",
        "We will often find it convenient\n",
        "to refer to features of our entire dataset of $n$ examples\n",
        "via the *design matrix* $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$.\n",
        "Here, $\\mathbf{X}$ contains one row for every example\n",
        "and one column for every feature.\n",
        "\n",
        "For a collection of features $\\mathbf{X}$,\n",
        "the predictions $\\hat{\\mathbf{y}} \\in \\mathbb{R}^n$\n",
        "can be expressed via the matrix-vector product:\n",
        "\n",
        "$${\\hat{\\mathbf{y}}} = \\mathbf{X} \\mathbf{w} + b,$$\n",
        "\n",
        "\n",
        "**Loss Function**\n",
        "\n",
        "When our prediction for an example $i$ is $\\hat{y}^{(i)}$\n",
        "and the corresponding true label is $y^{(i)}$,\n",
        "the squared error is given by:\n",
        "\n",
        "$$l^{(i)}(\\mathbf{w}, b) = \\frac{1}{2} \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2.$$\n",
        "\n",
        "To measure the quality of a model on the entire dataset of $n$ examples,\n",
        "we simply average (or equivalently, sum)\n",
        "the losses on the training set.\n",
        "\n",
        "$$L(\\mathbf{w}, b) =\\frac{1}{n}\\sum_{i=1}^n l^{(i)}(\\mathbf{w}, b) =\\frac{1}{n} \\sum_{i=1}^n \\frac{1}{2}\\left(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b - y^{(i)}\\right)^2.$$\n",
        "\n",
        "When training the model, we want to find parameters ($\\mathbf{w}^*, b^*$)\n",
        "that minimize the total loss across all training examples:\n",
        "\n",
        "$$\\mathbf{w}^*, b^* = \\operatorname*{argmin}_{\\mathbf{w}, b}\\  L(\\mathbf{w}, b).$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eddedadc-6641-4c7a-8134-79549b655a62",
      "metadata": {
        "id": "eddedadc-6641-4c7a-8134-79549b655a62"
      },
      "source": [
        "**Minibatch Stochastic Gradient Descent**\n",
        "\n",
        "We can express the update mathematically as follows\n",
        "($\\partial$ denotes the partial derivative):\n",
        "\n",
        "$$(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\partial_{(\\mathbf{w},b)} l^{(i)}(\\mathbf{w},b).$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5b67706-78b0-428a-b984-03e8a44f2daf",
      "metadata": {
        "id": "b5b67706-78b0-428a-b984-03e8a44f2daf"
      },
      "source": [
        "## Synthetic Data, Simple Model\n",
        "### Generating the Dataset\n",
        "\n",
        "To keep things simple, we will [**construct an artificial dataset\n",
        "according to a linear model with additive noise.**]\n",
        "\n",
        "In the following code snippet, we generate a dataset\n",
        "containing 1000 examples, each consisting of 2 features\n",
        "sampled from a standard normal distribution.\n",
        "Thus our synthetic dataset will be a matrix\n",
        "$\\mathbf{X}\\in \\mathbb{R}^{1000 \\times 2}$.\n",
        "\n",
        "(**The true parameters generating our dataset will be\n",
        "$\\mathbf{w} = [2, -3.4]^\\top$ and $b = 4.2$,\n",
        "and**) our synthetic labels will be assigned according\n",
        "to the following linear model with the noise term $\\epsilon$:\n",
        "\n",
        "(**$$\\mathbf{y}= \\mathbf{X} \\mathbf{w} + b + \\mathbf\\epsilon.$$**)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w_true = tf.Variable([[2],[-3.4]])\n",
        "b_true = tf.Variable(4.2)"
      ],
      "metadata": {
        "id": "q_Jod8HxDCWZ"
      },
      "id": "q_Jod8HxDCWZ",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6c56cf52-1cbe-4f80-9551-9988b28fe967",
      "metadata": {
        "origin_pos": 6,
        "tab": [
          "tensorflow"
        ],
        "id": "6c56cf52-1cbe-4f80-9551-9988b28fe967"
      },
      "outputs": [],
      "source": [
        "def synthetic_data(w, b, num_examples):  #@save\n",
        "    \"\"\"Generate y = Xw + b + noise.\"\"\"\n",
        "    X = tf.zeros((num_examples, w.shape[0]))\n",
        "    X += tf.random.normal(shape=X.shape)\n",
        "    y = tf.matmul(X, tf.reshape(w, (-1, 1))) + b\n",
        "    y += tf.random.normal(shape=y.shape, stddev=0.01)\n",
        "    y = tf.reshape(y, (-1, 1))\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6f7fc2ce-cdd3-45f0-b632-f5b7fbd38155",
      "metadata": {
        "origin_pos": 7,
        "tab": [
          "tensorflow"
        ],
        "id": "6f7fc2ce-cdd3-45f0-b632-f5b7fbd38155"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(5)\n",
        "true_w = tf.constant([2, -3.4])\n",
        "true_b = 4.2\n",
        "features, labels = synthetic_data(true_w, true_b, 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a088e27d-495b-461f-b483-5eaaa97d1dc8",
      "metadata": {
        "origin_pos": 9,
        "tab": [
          "tensorflow"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a088e27d-495b-461f-b483-5eaaa97d1dc8",
        "outputId": "1e3a9da2-02e8-4348-9338-92a98bcfb247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features: tf.Tensor(\n",
            "[[-0.18030666 -0.95028627]\n",
            " [-0.03964049 -0.7425406 ]\n",
            " [ 1.3231523  -0.61854804]\n",
            " ...\n",
            " [-0.19561373 -0.67268133]\n",
            " [ 2.0813875  -0.05136034]\n",
            " [ 0.50424373 -0.4713399 ]], shape=(1000, 2), dtype=float32) \n",
            "label: tf.Tensor([7.0726256], shape=(1,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print('features:', features,'\\nlabel:', labels[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af9a27cb-fcac-4856-99cb-724fa649c9a9",
      "metadata": {
        "origin_pos": 10,
        "id": "af9a27cb-fcac-4856-99cb-724fa649c9a9"
      },
      "source": [
        "By generating a scatter plot using the second feature `features[:, 1]` and `labels`,\n",
        "we can clearly observe the linear correlation between the two.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8cbcb65e-1376-4879-8a6c-5dc2dbc4c945",
      "metadata": {
        "origin_pos": 11,
        "tab": [
          "tensorflow"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "8cbcb65e-1376-4879-8a6c-5dc2dbc4c945",
        "outputId": "0e82e256-b4f6-4ec2-aaab-9ff848de4dc9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mjpg_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'svg'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0msvg_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'pdf'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mpdf_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pdf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2057\u001b[0m         \"\"\"\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m_get_output_canvas\u001b[0;34m(self, fmt)\u001b[0m\n\u001b[1;32m   1991\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m             \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mget_registered_canvas_class\u001b[0;34m(format)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbackend\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcanvas\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mBackend\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhandling\u001b[0m \u001b[0mfile\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mdescription\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mDescription\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_svg.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont_manager\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m from matplotlib.backend_bases import (\n\u001b[0m\u001b[1;32m     19\u001b[0m      \u001b[0m_Backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_check_savefig_extra_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigureManagerBase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m      RendererBase)\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name '_check_savefig_extra_args' from 'matplotlib.backend_bases' (/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 252x180 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "d2l.set_figsize()\n",
        "# The semicolon is for displaying the plot only\n",
        "d2l.plt.scatter(features[:, (1)].numpy(), labels.numpy(), 1);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36253bc0-ba53-410c-86bb-7a2eb11f9592",
      "metadata": {
        "origin_pos": 5,
        "tags": [],
        "id": "36253bc0-ba53-410c-86bb-7a2eb11f9592"
      },
      "source": [
        "### Reading the Dataset\n",
        "\n",
        "In the following code [**call upon the existing API in a framework to read data.**]\n",
        "We pass in `features` and `labels` as arguments and specify `batch_size`\n",
        "when instantiating a data iterator object.\n",
        "Besides, the boolean value `is_train`\n",
        "indicates whether or not\n",
        "we want the data iterator object to shuffle the data\n",
        "on each epoch (pass through the dataset).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c28419fa-707f-4a30-8d28-f18ab5d73c31",
      "metadata": {
        "id": "c28419fa-707f-4a30-8d28-f18ab5d73c31"
      },
      "source": [
        "1. **Use the tf function from_tensor_slices to generate a tf dataset object with batch_size as input**\n",
        "2. **Use is_train flag to determine whether to shuffle the dataset or not**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "53aaab37-4b35-4ff3-9d72-292d260838a9",
      "metadata": {
        "origin_pos": 8,
        "tab": [
          "tensorflow"
        ],
        "id": "53aaab37-4b35-4ff3-9d72-292d260838a9"
      },
      "outputs": [],
      "source": [
        "def load_array(data_arrays, batch_size, is_train=True):  #@save\n",
        "    \"\"\"Construct a TensorFlow data iterator.\"\"\"\n",
        "    #### YOUR CODE HERE ###\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(data_arrays)\\\n",
        "    .batch(batch_size)\n",
        "    dataset = dataset.shuffle(1000) if is_train else dataset\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1421cf52-54d8-4341-816c-a5d095bfb8c3",
      "metadata": {
        "origin_pos": 9,
        "tab": [
          "tensorflow"
        ],
        "id": "1421cf52-54d8-4341-816c-a5d095bfb8c3"
      },
      "outputs": [],
      "source": [
        "batch_size = 10\n",
        "data_iter = load_array((features, labels), batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6e0c589-effb-40ba-8149-3309692fed48",
      "metadata": {
        "origin_pos": 10,
        "id": "d6e0c589-effb-40ba-8149-3309692fed48"
      },
      "source": [
        "3. **Use `iter` to construct a Python iterator and use `next` to obtain the first item from the iterator.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2144c8a5-c59c-4886-af3b-8f4353e8f7c6",
      "metadata": {
        "origin_pos": 11,
        "tab": [
          "tensorflow"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2144c8a5-c59c-4886-af3b-8f4353e8f7c6",
        "outputId": "9c4c53c2-4c55-4162-e19d-fd12e141e8d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
              " array([[ 1.3564043e+00, -5.4133570e-01],\n",
              "        [-1.0421329e+00,  2.0101453e-01],\n",
              "        [-5.7323533e-01,  9.6179819e-01],\n",
              "        [ 9.9003541e-01, -1.0166390e+00],\n",
              "        [-2.7223310e-01, -4.9159122e-01],\n",
              "        [-8.1928289e-01, -9.0086297e-04],\n",
              "        [-2.0796096e+00,  8.4328723e-01],\n",
              "        [ 3.0477965e-01,  2.0460723e-01],\n",
              "        [ 1.1995399e+00,  2.9454825e+00],\n",
              "        [-5.4580241e-01, -6.5089208e-01]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
              " array([[ 8.755783  ],\n",
              "        [ 1.4219627 ],\n",
              "        [-0.21046317],\n",
              "        [ 9.629394  ],\n",
              "        [ 5.3383512 ],\n",
              "        [ 2.5792086 ],\n",
              "        [-2.8150222 ],\n",
              "        [ 4.1173363 ],\n",
              "        [-3.4104102 ],\n",
              "        [ 5.3102717 ]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "### YOUR CODE HERE ###\n",
        "iterator = iter(data_iter)\n",
        "iterator.next()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24da4a06-3978-49c2-bcf4-cb4c1ae64f49",
      "metadata": {
        "origin_pos": 15,
        "id": "24da4a06-3978-49c2-bcf4-cb4c1ae64f49"
      },
      "source": [
        "4. **Explain what the output shape in the prvious tensors means:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7eda004-0643-4132-b737-c1f2fc2049d9",
      "metadata": {
        "origin_pos": 16,
        "tab": [
          "tensorflow"
        ],
        "id": "c7eda004-0643-4132-b737-c1f2fc2049d9"
      },
      "source": [
        "**Answer:**\n",
        "first array is for features batch (10,2), and second is for labels batch (10,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c83f595-3746-435e-a824-9b4011a5aa40",
      "metadata": {
        "id": "5c83f595-3746-435e-a824-9b4011a5aa40"
      },
      "source": [
        "5. **How many TOTAL batches can be generated by **ENTIRE** data_iter ?** --> batches in data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88eb5391-71a5-45ef-8af3-8f6a33b7793c",
      "metadata": {
        "origin_pos": 16,
        "tab": [
          "tensorflow"
        ],
        "id": "88eb5391-71a5-45ef-8af3-8f6a33b7793c"
      },
      "source": [
        "**Answer:** 1000 data samples devided by batch = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71628cba-f449-4139-a02a-f4b9e6b53545",
      "metadata": {
        "origin_pos": 17,
        "tags": [],
        "id": "71628cba-f449-4139-a02a-f4b9e6b53545"
      },
      "source": [
        "### Initializing Model Parameters\n",
        "\n",
        "6. **Initialize weights by sampling random numbers from a normal distribution with mean 0 and a standard deviation of 0.01, and setting the bias to 0.**\n",
        "\n",
        "Note: For the shapes of the weights and bias, look at the generating a dataset part\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "db96e147-7256-4a1e-8c8a-6b89df19f117",
      "metadata": {
        "origin_pos": 20,
        "tab": [
          "tensorflow"
        ],
        "id": "db96e147-7256-4a1e-8c8a-6b89df19f117"
      },
      "outputs": [],
      "source": [
        "## YOUR CODE HERE ##\n",
        "np.random.seed(42)\n",
        "w = tf.Variable(tf.random.normal([2,1],mean=0.0, stddev=0.01))\n",
        "b = tf.Variable(tf.zeros(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09bbcd34-e487-4751-b8ff-a0f932350562",
      "metadata": {
        "origin_pos": 21,
        "id": "09bbcd34-e487-4751-b8ff-a0f932350562"
      },
      "source": [
        "### Defining the Model\n",
        "\n",
        "7. [**define our model, relating its inputs and parameters to its outputs.**]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a892f99c-9846-4b4c-bf89-dd552ca2fd26",
      "metadata": {
        "origin_pos": 22,
        "tab": [
          "tensorflow"
        ],
        "id": "a892f99c-9846-4b4c-bf89-dd552ca2fd26"
      },
      "outputs": [],
      "source": [
        "def linreg(X, w, b):  \n",
        "    \"\"\"The linear regression model.\"\"\"\n",
        "    ## YOUR CODE HERE ##\n",
        "    model = tf.matmul(X, w) + b\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78acdc39-21c6-4125-b0de-b7a14a9c93eb",
      "metadata": {
        "origin_pos": 23,
        "id": "78acdc39-21c6-4125-b0de-b7a14a9c93eb"
      },
      "source": [
        "### Defining the Loss Function\n",
        "\n",
        "8. (**define the loss function**): the squared loss function\n",
        "as described in Loss Function definition above.\n",
        "\n",
        "Note: In the implementation, you need to transform the true value `y`\n",
        "into the predicted value's shape `y_hat`.\n",
        "The result returned by the following function\n",
        "will also have the same shape as `y_hat`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "37e04bc2-0d67-4204-b0bf-b99ff8a1d0d3",
      "metadata": {
        "origin_pos": 24,
        "tab": [
          "tensorflow"
        ],
        "id": "37e04bc2-0d67-4204-b0bf-b99ff8a1d0d3"
      },
      "outputs": [],
      "source": [
        "def squared_loss(y_hat, y):  \n",
        "    \"\"\"Squared loss.\"\"\"\n",
        "    ## YOUR CODE HERE ##\n",
        "    return (1/2)*(tf.reshape(y,y_hat.shape) - y_hat)**2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "212f6a87-1c81-4aa1-aebe-41334d719398",
      "metadata": {
        "origin_pos": 25,
        "id": "212f6a87-1c81-4aa1-aebe-41334d719398"
      },
      "source": [
        "### Defining the Optimization Algorithm\n",
        "\n",
        "At each step, using one minibatch randomly drawn from our dataset,\n",
        "we will estimate the gradient of the loss with respect to our parameters.\n",
        "Next, we will update our parameters\n",
        "in the direction that may reduce the loss.\n",
        "\n",
        "9. **Filll in the missing function below to apply the minibatch stochastic gradient descent update, given a set of parameters, a learning rate, and a batch size.**\n",
        "\n",
        "Note: use assign_sub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ddfe9ccd-271e-4fc3-ab9a-3720d6bf4b23",
      "metadata": {
        "origin_pos": 28,
        "tab": [
          "tensorflow"
        ],
        "id": "ddfe9ccd-271e-4fc3-ab9a-3720d6bf4b23"
      },
      "outputs": [],
      "source": [
        "def sgd(params, grads, lr, batch_size):  \n",
        "    \"\"\"Minibatch stochastic gradient descent.\"\"\"\n",
        "    ## YOUR CODE HERE ##\n",
        "    # data_iter = load_array((features, labels), batch_size)\n",
        "    # iterator = iter(data_iter)\n",
        "    # for i in range(100):\n",
        "    #   with tf.GradientTape() as tape:\n",
        "    #     y = squared_loss(iterator.next()[0].numpy()*w + b, iterator.next()[1].numpy())\n",
        "\n",
        "    #   sum_d_dslope = sum(tape.gradient(y,w))\n",
        "    #   sum_d_dbias = sum(tape.gradient(y,b))\n",
        "    #   w = w - sum_d_dslope * lr\n",
        "    #   b = b - sum_d_dbias * lr\n",
        "    # return [w,b]\n",
        "    for param, grad in zip(params, grads):\n",
        "        param.assign_sub(lr*grad/batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9016fa58-4d4b-44b1-91a1-6f1e8995c9f7",
      "metadata": {
        "origin_pos": 29,
        "id": "9016fa58-4d4b-44b1-91a1-6f1e8995c9f7"
      },
      "source": [
        "### Training\n",
        "\n",
        "10. **Implement the following loop**\n",
        "\n",
        "* For each epoch :\n",
        "    * Initialize parameters $(\\mathbf{w}, b)$\n",
        "    * Repeat until done\n",
        "        * Compute gradient $\\mathbf{g} \\leftarrow \\partial_{(\\mathbf{w},b)} \\frac{1}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} l(\\mathbf{x}^{(i)}, y^{(i)}, \\mathbf{w}, b)$\n",
        "        * Update parameters $(\\mathbf{w}, b) \\leftarrow (\\mathbf{w}, b) - \\eta \\mathbf{g}$\n",
        "    * Print the loss at the end of each epoch\n",
        "\n",
        "In each *epoch*,\n",
        "we will iterate through the entire dataset\n",
        "(using the `data_iter` function) once\n",
        "passing through every example in the training dataset\n",
        ".\n",
        "\n",
        "\n",
        "Set the number of epochs `num_epochs` and the learning rate `lr` to 3 and 0.03, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "50a93813-59c4-48e7-beaf-d27fb707a96f",
      "metadata": {
        "origin_pos": 30,
        "tab": [
          "tensorflow"
        ],
        "id": "50a93813-59c4-48e7-beaf-d27fb707a96f"
      },
      "outputs": [],
      "source": [
        "lr = 0.03\n",
        "num_epochs = 3\n",
        "net = linreg\n",
        "loss = squared_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7f2d2d6e-1661-4737-b135-887221607b48",
      "metadata": {
        "origin_pos": 33,
        "tab": [
          "tensorflow"
        ],
        "id": "7f2d2d6e-1661-4737-b135-887221607b48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2fb0a7a-841b-4c11-d778-f8b5ec45526f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.05070346, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00023314875, shape=(), dtype=float32)\n",
            "tf.Tensor(5.435554e-05, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "## YOUR CODE HERE ##\n",
        "for i in range(num_epochs): \n",
        "  data_iter = load_array((features, labels), batch_size)\n",
        "  iterator = iter(data_iter)\n",
        "\n",
        "  for j in range(100):\n",
        "    batch = iterator.next()\n",
        "    with tf.GradientTape() as tape:\n",
        "      Loss = loss(net(batch[0], w, b), batch[1])\n",
        "    dl_dw, dl_db = tape.gradient(Loss, [w, b])\n",
        "    sgd([w, b], [dl_dw, dl_db], lr, batch_size)\n",
        "\n",
        "  loss_value = loss(net(features, w, b), labels)\n",
        "  print(tf.reduce_mean(loss_value))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "393f4953-35dc-46c1-b495-96172232bc3f",
      "metadata": {
        "origin_pos": 34,
        "id": "393f4953-35dc-46c1-b495-96172232bc3f"
      },
      "source": [
        "In this case, because we synthesized the dataset ourselves,\n",
        "we know precisely what the true parameters are.\n",
        "\n",
        "11. [**evaluate our success in training by comparing the true parameters with those that we learned**] through our training loop. They should turn out to be very close to each other.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c99daff3-745a-43fd-898e-bbf1e3804c78",
      "metadata": {
        "origin_pos": 35,
        "tab": [
          "tensorflow"
        ],
        "id": "c99daff3-745a-43fd-898e-bbf1e3804c78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "936ac821-6ff1-44b9-c62c-38bb557df9f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error in estimating w: [[0.00013876]\n",
            " [0.00037291]]\n",
            "error in estimating b: [0.00012738]\n"
          ]
        }
      ],
      "source": [
        "## YOUR CODE HERE ##\n",
        "print(f'error in estimating w: {(w_true - w)/w_true}')\n",
        "print(f'error in estimating b: {(b_true - b)/b_true}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f7b518a-c2ac-4f0e-941b-98d300ed9963",
      "metadata": {
        "id": "3f7b518a-c2ac-4f0e-941b-98d300ed9963"
      },
      "source": [
        "## Part 2  Diabetes Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06b07d9c-b52e-4f52-8e70-f7a4bebd63bb",
      "metadata": {
        "id": "06b07d9c-b52e-4f52-8e70-f7a4bebd63bb"
      },
      "source": [
        "In this section, we will use SKLEARN's Diabetes dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0cef42e-4494-4f16-b2d2-7cfe68c51e3d",
      "metadata": {
        "id": "e0cef42e-4494-4f16-b2d2-7cfe68c51e3d"
      },
      "source": [
        "### Loading the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2aea7770-afb6-45f2-93b1-b9c72df36bc0",
      "metadata": {
        "id": "2aea7770-afb6-45f2-93b1-b9c72df36bc0"
      },
      "source": [
        "1. **Load the Diabetes dataset from sklearn**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f07dc3b6-c48e-4a37-8f73-3500f344e717",
      "metadata": {
        "id": "f07dc3b6-c48e-4a37-8f73-3500f344e717"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "## YOUR CODE HERE ##\n",
        "# Load the diabetes dataset\n",
        "dataset = load_diabetes()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa95939c-f94a-4383-9e4b-18c86af1cebf",
      "metadata": {
        "id": "aa95939c-f94a-4383-9e4b-18c86af1cebf"
      },
      "source": [
        "2. **Look at the keys of diabetes_dataset dictionary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "1c92cb43-cb3d-47f1-8535-c4439f585412",
      "metadata": {
        "id": "1c92cb43-cb3d-47f1-8535-c4439f585412",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c80b91-3ec9-4a92-8175-8b8b12eecefe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'DESCR', 'feature_names', 'data_filename', 'target_filename', 'data_module'])\n"
          ]
        }
      ],
      "source": [
        "## YOUR CODE HERE ##\n",
        "\n",
        "### Look at keys to determine the data\n",
        "print(dataset.keys())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "484a2460-7023-4468-9399-3a40d00ba55c",
      "metadata": {
        "id": "484a2460-7023-4468-9399-3a40d00ba55c"
      },
      "source": [
        "3. **Use the key DESCR to understand the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "87437737-e0d0-4e18-a841-ab214ed2261b",
      "metadata": {
        "id": "87437737-e0d0-4e18-a841-ab214ed2261b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a30ab945-fafd-42eb-aa33-b988205d4ce3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _diabetes_dataset:\n",
            "\n",
            "Diabetes dataset\n",
            "----------------\n",
            "\n",
            "Ten baseline variables, age, sex, body mass index, average blood\n",
            "pressure, and six blood serum measurements were obtained for each of n =\n",
            "442 diabetes patients, as well as the response of interest, a\n",
            "quantitative measure of disease progression one year after baseline.\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "  :Number of Instances: 442\n",
            "\n",
            "  :Number of Attributes: First 10 columns are numeric predictive values\n",
            "\n",
            "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
            "\n",
            "  :Attribute Information:\n",
            "      - age     age in years\n",
            "      - sex\n",
            "      - bmi     body mass index\n",
            "      - bp      average blood pressure\n",
            "      - s1      tc, total serum cholesterol\n",
            "      - s2      ldl, low-density lipoproteins\n",
            "      - s3      hdl, high-density lipoproteins\n",
            "      - s4      tch, total cholesterol / HDL\n",
            "      - s5      ltg, possibly log of serum triglycerides level\n",
            "      - s6      glu, blood sugar level\n",
            "\n",
            "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
            "\n",
            "Source URL:\n",
            "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
            "\n",
            "For more information see:\n",
            "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
            "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
          ]
        }
      ],
      "source": [
        "## YOUR CODE HERE ##\n",
        "print(dataset.DESCR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6472180c-ebb8-44f9-8bab-c507e256ef39",
      "metadata": {
        "id": "6472180c-ebb8-44f9-8bab-c507e256ef39"
      },
      "source": [
        "4. **Save the data and target variables in numpy arrays and print their shapes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "8fc2a160-b33f-44c5-83a7-08beb821a64a",
      "metadata": {
        "id": "8fc2a160-b33f-44c5-83a7-08beb821a64a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7881c22c-5f63-4d31-ac65-a547c044bda8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of data is: (442, 10)\n",
            "The shape of targets is: (442,)\n",
            "I have f = 10 features!\n",
            "I have m = 442 examples!\n"
          ]
        }
      ],
      "source": [
        "### START CODE HERE ### (≈ 2 lines of code)\n",
        "data = dataset['data']\n",
        "targets = dataset['target']\n",
        "### END CODE HERE ###\n",
        "\n",
        "print ('The shape of data is: ' + str(data.shape))\n",
        "print ('The shape of targets is: ' + str(targets.shape))\n",
        "print ('I have f = %d features!' % (data.shape[1]))\n",
        "print ('I have m = %d examples!' % (data.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52f4ad51-a6a3-4cfc-9c64-6e7a44545d66",
      "metadata": {
        "id": "52f4ad51-a6a3-4cfc-9c64-6e7a44545d66"
      },
      "source": [
        "5. **What are the ranges of each column in features and the target column?**\n",
        "    - *Hint* you might find it helpful to convert to pandas dataframe and use \".describe\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "1e4d03cc-c705-4e4e-81f7-6d49a6e86fbd",
      "metadata": {
        "id": "1e4d03cc-c705-4e4e-81f7-6d49a6e86fbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "7e44f5e1-2154-4249-a8ff-350b693c71f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                age           sex           bmi            bp            s1  \\\n",
              "count  4.420000e+02  4.420000e+02  4.420000e+02  4.420000e+02  4.420000e+02   \n",
              "mean  -3.639623e-16  1.309912e-16 -8.013951e-16  1.289818e-16 -9.042540e-17   \n",
              "std    4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02   \n",
              "min   -1.072256e-01 -4.464164e-02 -9.027530e-02 -1.123996e-01 -1.267807e-01   \n",
              "25%   -3.729927e-02 -4.464164e-02 -3.422907e-02 -3.665645e-02 -3.424784e-02   \n",
              "50%    5.383060e-03 -4.464164e-02 -7.283766e-03 -5.670611e-03 -4.320866e-03   \n",
              "75%    3.807591e-02  5.068012e-02  3.124802e-02  3.564384e-02  2.835801e-02   \n",
              "max    1.107267e-01  5.068012e-02  1.705552e-01  1.320442e-01  1.539137e-01   \n",
              "\n",
              "                 s2            s3            s4            s5            s6  \\\n",
              "count  4.420000e+02  4.420000e+02  4.420000e+02  4.420000e+02  4.420000e+02   \n",
              "mean   1.301121e-16 -4.563971e-16  3.863174e-16 -3.848103e-16 -3.398488e-16   \n",
              "std    4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02   \n",
              "min   -1.156131e-01 -1.023071e-01 -7.639450e-02 -1.260974e-01 -1.377672e-01   \n",
              "25%   -3.035840e-02 -3.511716e-02 -3.949338e-02 -3.324879e-02 -3.317903e-02   \n",
              "50%   -3.819065e-03 -6.584468e-03 -2.592262e-03 -1.947634e-03 -1.077698e-03   \n",
              "75%    2.984439e-02  2.931150e-02  3.430886e-02  3.243323e-02  2.791705e-02   \n",
              "max    1.987880e-01  1.811791e-01  1.852344e-01  1.335990e-01  1.356118e-01   \n",
              "\n",
              "           target  \n",
              "count  442.000000  \n",
              "mean   152.133484  \n",
              "std     77.093005  \n",
              "min     25.000000  \n",
              "25%     87.000000  \n",
              "50%    140.500000  \n",
              "75%    211.500000  \n",
              "max    346.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3815acdd-06ae-4864-a83f-c1ecf443f9d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>bp</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4.420000e+02</td>\n",
              "      <td>4.420000e+02</td>\n",
              "      <td>4.420000e+02</td>\n",
              "      <td>4.420000e+02</td>\n",
              "      <td>4.420000e+02</td>\n",
              "      <td>4.420000e+02</td>\n",
              "      <td>4.420000e+02</td>\n",
              "      <td>4.420000e+02</td>\n",
              "      <td>4.420000e+02</td>\n",
              "      <td>4.420000e+02</td>\n",
              "      <td>442.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-3.639623e-16</td>\n",
              "      <td>1.309912e-16</td>\n",
              "      <td>-8.013951e-16</td>\n",
              "      <td>1.289818e-16</td>\n",
              "      <td>-9.042540e-17</td>\n",
              "      <td>1.301121e-16</td>\n",
              "      <td>-4.563971e-16</td>\n",
              "      <td>3.863174e-16</td>\n",
              "      <td>-3.848103e-16</td>\n",
              "      <td>-3.398488e-16</td>\n",
              "      <td>152.133484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.761905e-02</td>\n",
              "      <td>4.761905e-02</td>\n",
              "      <td>4.761905e-02</td>\n",
              "      <td>4.761905e-02</td>\n",
              "      <td>4.761905e-02</td>\n",
              "      <td>4.761905e-02</td>\n",
              "      <td>4.761905e-02</td>\n",
              "      <td>4.761905e-02</td>\n",
              "      <td>4.761905e-02</td>\n",
              "      <td>4.761905e-02</td>\n",
              "      <td>77.093005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.072256e-01</td>\n",
              "      <td>-4.464164e-02</td>\n",
              "      <td>-9.027530e-02</td>\n",
              "      <td>-1.123996e-01</td>\n",
              "      <td>-1.267807e-01</td>\n",
              "      <td>-1.156131e-01</td>\n",
              "      <td>-1.023071e-01</td>\n",
              "      <td>-7.639450e-02</td>\n",
              "      <td>-1.260974e-01</td>\n",
              "      <td>-1.377672e-01</td>\n",
              "      <td>25.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-3.729927e-02</td>\n",
              "      <td>-4.464164e-02</td>\n",
              "      <td>-3.422907e-02</td>\n",
              "      <td>-3.665645e-02</td>\n",
              "      <td>-3.424784e-02</td>\n",
              "      <td>-3.035840e-02</td>\n",
              "      <td>-3.511716e-02</td>\n",
              "      <td>-3.949338e-02</td>\n",
              "      <td>-3.324879e-02</td>\n",
              "      <td>-3.317903e-02</td>\n",
              "      <td>87.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.383060e-03</td>\n",
              "      <td>-4.464164e-02</td>\n",
              "      <td>-7.283766e-03</td>\n",
              "      <td>-5.670611e-03</td>\n",
              "      <td>-4.320866e-03</td>\n",
              "      <td>-3.819065e-03</td>\n",
              "      <td>-6.584468e-03</td>\n",
              "      <td>-2.592262e-03</td>\n",
              "      <td>-1.947634e-03</td>\n",
              "      <td>-1.077698e-03</td>\n",
              "      <td>140.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.807591e-02</td>\n",
              "      <td>5.068012e-02</td>\n",
              "      <td>3.124802e-02</td>\n",
              "      <td>3.564384e-02</td>\n",
              "      <td>2.835801e-02</td>\n",
              "      <td>2.984439e-02</td>\n",
              "      <td>2.931150e-02</td>\n",
              "      <td>3.430886e-02</td>\n",
              "      <td>3.243323e-02</td>\n",
              "      <td>2.791705e-02</td>\n",
              "      <td>211.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.107267e-01</td>\n",
              "      <td>5.068012e-02</td>\n",
              "      <td>1.705552e-01</td>\n",
              "      <td>1.320442e-01</td>\n",
              "      <td>1.539137e-01</td>\n",
              "      <td>1.987880e-01</td>\n",
              "      <td>1.811791e-01</td>\n",
              "      <td>1.852344e-01</td>\n",
              "      <td>1.335990e-01</td>\n",
              "      <td>1.356118e-01</td>\n",
              "      <td>346.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3815acdd-06ae-4864-a83f-c1ecf443f9d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3815acdd-06ae-4864-a83f-c1ecf443f9d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3815acdd-06ae-4864-a83f-c1ecf443f9d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "### START CODE HERE ###\n",
        "dataFrame = pd.DataFrame(data= np.c_[dataset['data'], dataset['target']],\n",
        "                     columns= dataset['feature_names'] + ['target'])\n",
        "dataFrame.describe()\n",
        "### END CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "742f762c-fe10-42be-a3d6-7cbb4df68c0d",
      "metadata": {
        "id": "742f762c-fe10-42be-a3d6-7cbb4df68c0d"
      },
      "source": [
        "### Preparing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c879c44-aec4-4c29-aa2a-76a1d48171e6",
      "metadata": {
        "id": "4c879c44-aec4-4c29-aa2a-76a1d48171e6"
      },
      "source": [
        "6. **Split the data into train and test set using sklearn train_test_split.** Have the test set as 10% of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "ced08578-8d2c-4e2b-ae34-4f6fa8f4326d",
      "metadata": {
        "id": "ced08578-8d2c-4e2b-ae34-4f6fa8f4326d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c749d918-c0e4-4437-a37a-b757171b1542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training data is (397, 10)\n",
            "Shape of training targets is (397,)\n",
            "Shape of test data is (45, 10)\n",
            "Shape of test targets is (45,)\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "### START CODE HERE ###\n",
        "# Split the data into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data, train_targets, test_targets = train_test_split(dataset['data'], dataset['target'], test_size=0.1)\n",
        "### END CODE HERE ###\n",
        "\n",
        "print(\"Shape of training data is\", train_data.shape)\n",
        "print(\"Shape of training targets is\", train_targets.shape)\n",
        "print(\"Shape of test data is\", test_data.shape)\n",
        "print(\"Shape of test targets is\", test_targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e18cbdeb-252c-450b-b85a-d35d5989f928",
      "metadata": {
        "id": "e18cbdeb-252c-450b-b85a-d35d5989f928"
      },
      "source": [
        "- *feature-wise normalization*: for each feature in the input data (a column in the input data matrix), we subtract the mean of the feature and divide by the standard deviation, so that the feature is centered around 0 and has a unit standard deviation. This is easily done in NumPy.\n",
        "- **Question:** Should we normalize features? WHY?\n",
        "    - ANSWER: yes, as normalization helps to converge faster"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e679d2b1-eded-4768-8954-c6cdfde3e207",
      "metadata": {
        "id": "e679d2b1-eded-4768-8954-c6cdfde3e207"
      },
      "source": [
        "7. **normalize the targets using standard normalization**\n",
        "\n",
        "Hint: Avoid leak between train and test data !!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "f18246d4-dbd8-403a-9db9-a72360eaaebb",
      "metadata": {
        "id": "f18246d4-dbd8-403a-9db9-a72360eaaebb"
      },
      "outputs": [],
      "source": [
        "### START CODE HERE ### (≈ 6 lines of code)\n",
        "mean_target_train = np.mean(train_targets)\n",
        "std_target_train = np.std(train_targets)\n",
        "train_targets = (train_targets - mean_target_train)/std_target_train\n",
        "# mean_target_test = np.mean(test_targets)\n",
        "# std_target_test = np.std(test_targets)\n",
        "test_targets = (test_targets - mean_target_train)/std_target_train\n",
        "### END CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "130ed50b-010c-488f-b1d0-aa2919fdf01d",
      "metadata": {
        "id": "130ed50b-010c-488f-b1d0-aa2919fdf01d"
      },
      "source": [
        "### Building your model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dca53c6-d8c6-4a93-876e-080cb537e98a",
      "metadata": {
        "id": "9dca53c6-d8c6-4a93-876e-080cb537e98a"
      },
      "source": [
        "7. **Use tf.keras.Sequential to build a model with:**\n",
        "    - 6 hidden layers each having 128 neurons and relu activation.\n",
        "    - 1 output layer\n",
        "    - use input_shape argument to specify input size in 1st layer\n",
        "- **Question:** How many neurons should be in output layer? What should be the activation?\n",
        "    - ANSWER: 1  , none"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "cc9bc68e-d3a4-42c6-b1e1-42c2c97fa651",
      "metadata": {
        "id": "cc9bc68e-d3a4-42c6-b1e1-42c2c97fa651"
      },
      "outputs": [],
      "source": [
        "def build_model(input_shape):\n",
        "    ### START CODE HERE ### ()\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu, input_shape=(10,)),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),  \n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
        "                                    tf.keras.layers.Dense(1)])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "cfe03837-d15a-4879-b9db-0477d01baa23",
      "metadata": {
        "id": "cfe03837-d15a-4879-b9db-0477d01baa23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e9e5753-28f1-4d0d-8644-4aff4e72ee11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 84,097\n",
            "Trainable params: 84,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Print the model summary\n",
        "input_shape=(train_data.shape[-1],)\n",
        "model = build_model(input_shape)\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "114f2e34-fa34-4312-bbe8-c929d350c89f",
      "metadata": {
        "id": "114f2e34-fa34-4312-bbe8-c929d350c89f"
      },
      "source": [
        "8. **Compile the model using optimizer=Adam, loss=mean squared loss, metrics=mean absoluute error:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "8a438445-aac4-4913-8012-6d7095b09ed1",
      "metadata": {
        "id": "8a438445-aac4-4913-8012-6d7095b09ed1"
      },
      "outputs": [],
      "source": [
        "### START CODE HERE ### ()\n",
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'mean_squared_error',\n",
        "              metrics=['mean_absolute_error'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9eb30a2-e09f-4298-8210-998eb79eb7a9",
      "metadata": {
        "id": "f9eb30a2-e09f-4298-8210-998eb79eb7a9"
      },
      "source": [
        "Note that we compile the model with the mse loss function—mean squared error, the\n",
        "square of the difference between the predictions and the targets. We’re also monitoring a new metric during training: mean absolute error (MAE). It’s the\n",
        "absolute value of the difference between the predictions and the targets."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36507d6f-cd6d-47fa-b74c-fd7e14c9d9ba",
      "metadata": {
        "id": "36507d6f-cd6d-47fa-b74c-fd7e14c9d9ba"
      },
      "source": [
        "9. **FIT the model using for 100 epochs, 64 batch size and a validation split of 0.15**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "1f63ab80-1353-4997-aba5-4e6299bee5d7",
      "metadata": {
        "tags": [],
        "id": "1f63ab80-1353-4997-aba5-4e6299bee5d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d33c6813-9a7a-4120-fb24-da3e09d4d789"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 1s 44ms/step - loss: 0.9607 - mean_absolute_error: 0.8395 - val_loss: 1.1176 - val_mean_absolute_error: 0.8940\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.8974 - mean_absolute_error: 0.8098 - val_loss: 0.9720 - val_mean_absolute_error: 0.8376\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.7295 - mean_absolute_error: 0.7323 - val_loss: 0.7000 - val_mean_absolute_error: 0.6867\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5595 - mean_absolute_error: 0.6162 - val_loss: 0.5704 - val_mean_absolute_error: 0.5734\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5512 - mean_absolute_error: 0.5773 - val_loss: 0.5467 - val_mean_absolute_error: 0.6096\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5001 - mean_absolute_error: 0.5947 - val_loss: 0.6094 - val_mean_absolute_error: 0.6271\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4982 - mean_absolute_error: 0.5742 - val_loss: 0.5108 - val_mean_absolute_error: 0.5952\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4616 - mean_absolute_error: 0.5612 - val_loss: 0.5265 - val_mean_absolute_error: 0.5702\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4908 - mean_absolute_error: 0.5464 - val_loss: 0.4796 - val_mean_absolute_error: 0.5560\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5143 - mean_absolute_error: 0.5793 - val_loss: 0.5021 - val_mean_absolute_error: 0.5757\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4633 - mean_absolute_error: 0.5466 - val_loss: 0.5565 - val_mean_absolute_error: 0.5970\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4351 - mean_absolute_error: 0.5436 - val_loss: 0.5160 - val_mean_absolute_error: 0.5819\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4290 - mean_absolute_error: 0.5357 - val_loss: 0.5051 - val_mean_absolute_error: 0.5583\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4259 - mean_absolute_error: 0.5165 - val_loss: 0.4609 - val_mean_absolute_error: 0.5367\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4133 - mean_absolute_error: 0.5213 - val_loss: 0.4627 - val_mean_absolute_error: 0.5285\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4053 - mean_absolute_error: 0.5058 - val_loss: 0.4606 - val_mean_absolute_error: 0.5262\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3960 - mean_absolute_error: 0.5062 - val_loss: 0.4651 - val_mean_absolute_error: 0.5272\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3947 - mean_absolute_error: 0.4980 - val_loss: 0.4538 - val_mean_absolute_error: 0.5195\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3748 - mean_absolute_error: 0.4870 - val_loss: 0.4531 - val_mean_absolute_error: 0.5207\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3723 - mean_absolute_error: 0.4827 - val_loss: 0.4563 - val_mean_absolute_error: 0.5192\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3746 - mean_absolute_error: 0.4907 - val_loss: 0.4740 - val_mean_absolute_error: 0.5267\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3654 - mean_absolute_error: 0.4842 - val_loss: 0.4748 - val_mean_absolute_error: 0.5224\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.3548 - mean_absolute_error: 0.4729 - val_loss: 0.4575 - val_mean_absolute_error: 0.5206\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3524 - mean_absolute_error: 0.4684 - val_loss: 0.4790 - val_mean_absolute_error: 0.5202\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3461 - mean_absolute_error: 0.4612 - val_loss: 0.4720 - val_mean_absolute_error: 0.5246\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.3338 - mean_absolute_error: 0.4565 - val_loss: 0.4921 - val_mean_absolute_error: 0.5278\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3398 - mean_absolute_error: 0.4699 - val_loss: 0.5499 - val_mean_absolute_error: 0.5493\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3449 - mean_absolute_error: 0.4572 - val_loss: 0.4950 - val_mean_absolute_error: 0.5695\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3496 - mean_absolute_error: 0.4740 - val_loss: 0.5347 - val_mean_absolute_error: 0.5471\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3364 - mean_absolute_error: 0.4560 - val_loss: 0.4812 - val_mean_absolute_error: 0.5199\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3160 - mean_absolute_error: 0.4356 - val_loss: 0.4957 - val_mean_absolute_error: 0.5287\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3058 - mean_absolute_error: 0.4320 - val_loss: 0.4687 - val_mean_absolute_error: 0.5283\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3138 - mean_absolute_error: 0.4493 - val_loss: 0.5381 - val_mean_absolute_error: 0.5461\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2998 - mean_absolute_error: 0.4371 - val_loss: 0.4829 - val_mean_absolute_error: 0.5225\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2855 - mean_absolute_error: 0.4181 - val_loss: 0.4955 - val_mean_absolute_error: 0.5417\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2890 - mean_absolute_error: 0.4316 - val_loss: 0.5939 - val_mean_absolute_error: 0.5662\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2855 - mean_absolute_error: 0.4229 - val_loss: 0.5004 - val_mean_absolute_error: 0.5217\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2607 - mean_absolute_error: 0.3992 - val_loss: 0.4983 - val_mean_absolute_error: 0.5225\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2592 - mean_absolute_error: 0.4006 - val_loss: 0.5678 - val_mean_absolute_error: 0.5597\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2620 - mean_absolute_error: 0.3959 - val_loss: 0.5664 - val_mean_absolute_error: 0.5657\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2905 - mean_absolute_error: 0.4228 - val_loss: 0.5189 - val_mean_absolute_error: 0.5358\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2740 - mean_absolute_error: 0.4125 - val_loss: 0.5184 - val_mean_absolute_error: 0.5573\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2645 - mean_absolute_error: 0.4011 - val_loss: 0.5206 - val_mean_absolute_error: 0.5264\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2404 - mean_absolute_error: 0.3846 - val_loss: 0.6234 - val_mean_absolute_error: 0.5806\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2577 - mean_absolute_error: 0.3920 - val_loss: 0.5241 - val_mean_absolute_error: 0.5337\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2287 - mean_absolute_error: 0.3749 - val_loss: 0.5000 - val_mean_absolute_error: 0.5438\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2352 - mean_absolute_error: 0.3852 - val_loss: 0.5748 - val_mean_absolute_error: 0.5586\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2107 - mean_absolute_error: 0.3627 - val_loss: 0.5757 - val_mean_absolute_error: 0.5573\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2023 - mean_absolute_error: 0.3489 - val_loss: 0.5508 - val_mean_absolute_error: 0.5407\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1925 - mean_absolute_error: 0.3447 - val_loss: 0.5995 - val_mean_absolute_error: 0.5689\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1831 - mean_absolute_error: 0.3412 - val_loss: 0.6176 - val_mean_absolute_error: 0.5868\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1855 - mean_absolute_error: 0.3385 - val_loss: 0.6282 - val_mean_absolute_error: 0.5863\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1761 - mean_absolute_error: 0.3260 - val_loss: 0.6465 - val_mean_absolute_error: 0.5871\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1851 - mean_absolute_error: 0.3366 - val_loss: 0.7090 - val_mean_absolute_error: 0.6170\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2028 - mean_absolute_error: 0.3631 - val_loss: 0.5833 - val_mean_absolute_error: 0.5446\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2304 - mean_absolute_error: 0.3672 - val_loss: 0.5283 - val_mean_absolute_error: 0.5468\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1758 - mean_absolute_error: 0.3379 - val_loss: 0.5320 - val_mean_absolute_error: 0.5413\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1610 - mean_absolute_error: 0.3124 - val_loss: 0.6454 - val_mean_absolute_error: 0.5826\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1673 - mean_absolute_error: 0.3225 - val_loss: 0.6679 - val_mean_absolute_error: 0.5866\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.1666 - mean_absolute_error: 0.3167 - val_loss: 0.5773 - val_mean_absolute_error: 0.5524\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.1529 - mean_absolute_error: 0.3101 - val_loss: 0.5425 - val_mean_absolute_error: 0.5396\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1595 - mean_absolute_error: 0.3098 - val_loss: 0.5575 - val_mean_absolute_error: 0.5562\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1375 - mean_absolute_error: 0.2930 - val_loss: 0.5612 - val_mean_absolute_error: 0.5579\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1255 - mean_absolute_error: 0.2782 - val_loss: 0.5596 - val_mean_absolute_error: 0.5485\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1072 - mean_absolute_error: 0.2507 - val_loss: 0.6032 - val_mean_absolute_error: 0.5739\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.1083 - mean_absolute_error: 0.2528 - val_loss: 0.6419 - val_mean_absolute_error: 0.5780\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1421 - mean_absolute_error: 0.2995 - val_loss: 0.5762 - val_mean_absolute_error: 0.5580\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1173 - mean_absolute_error: 0.2583 - val_loss: 0.5886 - val_mean_absolute_error: 0.5543\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1281 - mean_absolute_error: 0.2869 - val_loss: 0.6814 - val_mean_absolute_error: 0.6034\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1473 - mean_absolute_error: 0.3045 - val_loss: 0.5938 - val_mean_absolute_error: 0.5537\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1206 - mean_absolute_error: 0.2786 - val_loss: 0.6605 - val_mean_absolute_error: 0.5979\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.1245 - mean_absolute_error: 0.2758 - val_loss: 0.6141 - val_mean_absolute_error: 0.5667\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1034 - mean_absolute_error: 0.2537 - val_loss: 0.5839 - val_mean_absolute_error: 0.5543\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0974 - mean_absolute_error: 0.2345 - val_loss: 0.5747 - val_mean_absolute_error: 0.5572\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0854 - mean_absolute_error: 0.2260 - val_loss: 0.6115 - val_mean_absolute_error: 0.5547\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.0835 - mean_absolute_error: 0.2186 - val_loss: 0.6278 - val_mean_absolute_error: 0.5872\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0803 - mean_absolute_error: 0.2229 - val_loss: 0.6243 - val_mean_absolute_error: 0.5696\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0887 - mean_absolute_error: 0.2334 - val_loss: 0.5975 - val_mean_absolute_error: 0.5710\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0791 - mean_absolute_error: 0.2150 - val_loss: 0.5886 - val_mean_absolute_error: 0.5562\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0649 - mean_absolute_error: 0.1982 - val_loss: 0.6433 - val_mean_absolute_error: 0.5785\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0639 - mean_absolute_error: 0.1900 - val_loss: 0.6452 - val_mean_absolute_error: 0.5669\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0555 - mean_absolute_error: 0.1763 - val_loss: 0.6693 - val_mean_absolute_error: 0.5822\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0554 - mean_absolute_error: 0.1738 - val_loss: 0.6346 - val_mean_absolute_error: 0.5708\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0545 - mean_absolute_error: 0.1787 - val_loss: 0.6419 - val_mean_absolute_error: 0.5605\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0485 - mean_absolute_error: 0.1641 - val_loss: 0.6700 - val_mean_absolute_error: 0.5815\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0490 - mean_absolute_error: 0.1638 - val_loss: 0.6589 - val_mean_absolute_error: 0.5759\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0415 - mean_absolute_error: 0.1502 - val_loss: 0.6465 - val_mean_absolute_error: 0.5759\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0402 - mean_absolute_error: 0.1507 - val_loss: 0.6586 - val_mean_absolute_error: 0.5776\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0394 - mean_absolute_error: 0.1462 - val_loss: 0.6344 - val_mean_absolute_error: 0.5653\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0411 - mean_absolute_error: 0.1540 - val_loss: 0.6612 - val_mean_absolute_error: 0.5814\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0493 - mean_absolute_error: 0.1690 - val_loss: 0.6392 - val_mean_absolute_error: 0.5848\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0415 - mean_absolute_error: 0.1524 - val_loss: 0.6416 - val_mean_absolute_error: 0.5713\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0424 - mean_absolute_error: 0.1526 - val_loss: 0.6413 - val_mean_absolute_error: 0.5734\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0463 - mean_absolute_error: 0.1605 - val_loss: 0.6543 - val_mean_absolute_error: 0.5775\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0456 - mean_absolute_error: 0.1652 - val_loss: 0.6202 - val_mean_absolute_error: 0.5440\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0454 - mean_absolute_error: 0.1616 - val_loss: 0.6053 - val_mean_absolute_error: 0.5472\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0481 - mean_absolute_error: 0.1675 - val_loss: 0.6226 - val_mean_absolute_error: 0.5587\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0404 - mean_absolute_error: 0.1503 - val_loss: 0.6513 - val_mean_absolute_error: 0.5841\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0392 - mean_absolute_error: 0.1496 - val_loss: 0.6392 - val_mean_absolute_error: 0.5788\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0361 - mean_absolute_error: 0.1426 - val_loss: 0.6231 - val_mean_absolute_error: 0.5548\n"
          ]
        }
      ],
      "source": [
        "### START CODE HERE ### ()\n",
        "history = model.fit(train_data, train_targets,  batch_size = 64, epochs=100, validation_split = 0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "e2000d08-a40d-4bc8-ac8c-87c30111c670",
      "metadata": {
        "id": "e2000d08-a40d-4bc8-ac8c-87c30111c670",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf51e360-24d7-4f8c-db6b-97a2c110eb1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 - 0s - loss: 0.8298 - mean_absolute_error: 0.7184 - 30ms/epoch - 15ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8297767043113708, 0.7183956503868103]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "\n",
        "model.evaluate(test_data, test_targets, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "a171c786-ce1f-4004-b096-75b5562bdf15",
      "metadata": {
        "id": "a171c786-ce1f-4004-b096-75b5562bdf15"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "3a0de6a8-b049-4221-972e-689b166c71aa",
      "metadata": {
        "id": "3a0de6a8-b049-4221-972e-689b166c71aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "d2bff48a-a3e8-499e-9444-58aecfde7d1b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mjpg_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'svg'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0msvg_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'pdf'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mpdf_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pdf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2057\u001b[0m         \"\"\"\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m_get_output_canvas\u001b[0;34m(self, fmt)\u001b[0m\n\u001b[1;32m   1991\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m             \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mget_registered_canvas_class\u001b[0;34m(format)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbackend\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcanvas\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mBackend\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhandling\u001b[0m \u001b[0mfile\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mdescription\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mDescription\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_svg.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont_manager\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m from matplotlib.backend_bases import (\n\u001b[0m\u001b[1;32m     19\u001b[0m      \u001b[0m_Backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_check_savefig_extra_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigureManagerBase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m      RendererBase)\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name '_check_savefig_extra_args' from 'matplotlib.backend_bases' (/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plot the training and validation loss\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss vs. epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fea592c-3cd2-4fb6-b32b-d9da751763fd",
      "metadata": {
        "id": "5fea592c-3cd2-4fb6-b32b-d9da751763fd"
      },
      "source": [
        "9. **Diagnose the learning curve:**\n",
        "    - Why is the validation loss much higher than training loss?\n",
        "    - What's this phenomenon called?\n",
        "    - Mention 3 methods to reduce this."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8fd101e-f9d1-49bc-9101-1157932be789",
      "metadata": {
        "id": "b8fd101e-f9d1-49bc-9101-1157932be789"
      },
      "source": [
        "- **answer**:\n",
        "    - because the curve is aligned to the training data so it fails to fit any additional data that doesn't fall in that curve\n",
        "    - overfitting\n",
        "    - Regularization, Train with more data, Addition of noise to the input data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f186ab89-4e72-4379-b458-843fbba8f1ef",
      "metadata": {
        "id": "f186ab89-4e72-4379-b458-843fbba8f1ef"
      },
      "source": [
        "10. **Use one of the methods you mentioned and retrain the model then plot the learning curves**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "aa69dd9f-6304-4115-a547-8f02caa613bf",
      "metadata": {
        "id": "aa69dd9f-6304-4115-a547-8f02caa613bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d593b194-e145-43f2-878c-9c23eeb91dee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 2s 108ms/step - loss: 7.3042 - mean_absolute_error: 0.8410 - val_loss: 7.0250 - val_mean_absolute_error: 0.9074\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 6.5792 - mean_absolute_error: 0.8333 - val_loss: 6.3397 - val_mean_absolute_error: 0.9001\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 5.9158 - mean_absolute_error: 0.8256 - val_loss: 5.7117 - val_mean_absolute_error: 0.8890\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 5.3097 - mean_absolute_error: 0.8145 - val_loss: 5.1318 - val_mean_absolute_error: 0.8722\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 4.7505 - mean_absolute_error: 0.7935 - val_loss: 4.5920 - val_mean_absolute_error: 0.8450\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 4.2298 - mean_absolute_error: 0.7619 - val_loss: 4.0767 - val_mean_absolute_error: 0.7887\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 3.7302 - mean_absolute_error: 0.6977 - val_loss: 3.5561 - val_mean_absolute_error: 0.7109\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 3.2808 - mean_absolute_error: 0.6257 - val_loss: 3.1547 - val_mean_absolute_error: 0.6274\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 2.9409 - mean_absolute_error: 0.5784 - val_loss: 2.8089 - val_mean_absolute_error: 0.6233\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 2.6383 - mean_absolute_error: 0.5696 - val_loss: 2.5879 - val_mean_absolute_error: 0.6139\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 2.4055 - mean_absolute_error: 0.5777 - val_loss: 2.3068 - val_mean_absolute_error: 0.5946\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 2.1894 - mean_absolute_error: 0.5651 - val_loss: 2.1003 - val_mean_absolute_error: 0.5810\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2.0101 - mean_absolute_error: 0.5630 - val_loss: 1.9503 - val_mean_absolute_error: 0.5775\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 1.8468 - mean_absolute_error: 0.5521 - val_loss: 1.8083 - val_mean_absolute_error: 0.6050\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 1.7048 - mean_absolute_error: 0.5644 - val_loss: 1.7056 - val_mean_absolute_error: 0.5959\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 1.5766 - mean_absolute_error: 0.5558 - val_loss: 1.5429 - val_mean_absolute_error: 0.5805\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 1.4663 - mean_absolute_error: 0.5560 - val_loss: 1.4527 - val_mean_absolute_error: 0.5800\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 1.3728 - mean_absolute_error: 0.5546 - val_loss: 1.3415 - val_mean_absolute_error: 0.5681\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 1.2818 - mean_absolute_error: 0.5483 - val_loss: 1.2623 - val_mean_absolute_error: 0.5703\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 1.2111 - mean_absolute_error: 0.5538 - val_loss: 1.1956 - val_mean_absolute_error: 0.5738\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.1478 - mean_absolute_error: 0.5569 - val_loss: 1.1497 - val_mean_absolute_error: 0.5748\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 1.0803 - mean_absolute_error: 0.5522 - val_loss: 1.0881 - val_mean_absolute_error: 0.5702\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 1.0258 - mean_absolute_error: 0.5503 - val_loss: 1.0393 - val_mean_absolute_error: 0.5744\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.9838 - mean_absolute_error: 0.5541 - val_loss: 1.0107 - val_mean_absolute_error: 0.5757\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.9389 - mean_absolute_error: 0.5440 - val_loss: 0.9596 - val_mean_absolute_error: 0.5785\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.9241 - mean_absolute_error: 0.5546 - val_loss: 0.9407 - val_mean_absolute_error: 0.5718\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.9009 - mean_absolute_error: 0.5651 - val_loss: 0.9480 - val_mean_absolute_error: 0.5889\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.8999 - mean_absolute_error: 0.5642 - val_loss: 0.9353 - val_mean_absolute_error: 0.6269\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.8668 - mean_absolute_error: 0.5802 - val_loss: 0.9657 - val_mean_absolute_error: 0.6171\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.8613 - mean_absolute_error: 0.5705 - val_loss: 0.8566 - val_mean_absolute_error: 0.5950\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.8150 - mean_absolute_error: 0.5685 - val_loss: 0.9030 - val_mean_absolute_error: 0.6059\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.8591 - mean_absolute_error: 0.5840 - val_loss: 0.8305 - val_mean_absolute_error: 0.5976\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.8519 - mean_absolute_error: 0.6109 - val_loss: 0.8272 - val_mean_absolute_error: 0.6068\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.7748 - mean_absolute_error: 0.5734 - val_loss: 0.8441 - val_mean_absolute_error: 0.6154\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.7428 - mean_absolute_error: 0.5640 - val_loss: 0.7999 - val_mean_absolute_error: 0.6045\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.7338 - mean_absolute_error: 0.5650 - val_loss: 0.8289 - val_mean_absolute_error: 0.6058\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.7292 - mean_absolute_error: 0.5590 - val_loss: 0.7648 - val_mean_absolute_error: 0.5877\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.7138 - mean_absolute_error: 0.5601 - val_loss: 0.7857 - val_mean_absolute_error: 0.5919\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.7078 - mean_absolute_error: 0.5515 - val_loss: 0.7387 - val_mean_absolute_error: 0.5784\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6924 - mean_absolute_error: 0.5547 - val_loss: 0.7429 - val_mean_absolute_error: 0.5769\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6972 - mean_absolute_error: 0.5533 - val_loss: 0.7294 - val_mean_absolute_error: 0.5755\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6800 - mean_absolute_error: 0.5471 - val_loss: 0.7223 - val_mean_absolute_error: 0.5818\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.6755 - mean_absolute_error: 0.5587 - val_loss: 0.7153 - val_mean_absolute_error: 0.5762\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.6709 - mean_absolute_error: 0.5509 - val_loss: 0.7116 - val_mean_absolute_error: 0.5679\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6671 - mean_absolute_error: 0.5449 - val_loss: 0.7172 - val_mean_absolute_error: 0.5715\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6622 - mean_absolute_error: 0.5470 - val_loss: 0.6983 - val_mean_absolute_error: 0.5767\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.6549 - mean_absolute_error: 0.5498 - val_loss: 0.7109 - val_mean_absolute_error: 0.5799\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.6486 - mean_absolute_error: 0.5463 - val_loss: 0.6799 - val_mean_absolute_error: 0.5604\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.6481 - mean_absolute_error: 0.5436 - val_loss: 0.6775 - val_mean_absolute_error: 0.5645\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6417 - mean_absolute_error: 0.5452 - val_loss: 0.7233 - val_mean_absolute_error: 0.5806\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.6736 - mean_absolute_error: 0.5542 - val_loss: 0.6850 - val_mean_absolute_error: 0.5807\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.6479 - mean_absolute_error: 0.5510 - val_loss: 0.6789 - val_mean_absolute_error: 0.5703\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6432 - mean_absolute_error: 0.5533 - val_loss: 0.6828 - val_mean_absolute_error: 0.5687\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6437 - mean_absolute_error: 0.5486 - val_loss: 0.6753 - val_mean_absolute_error: 0.5730\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.6300 - mean_absolute_error: 0.5494 - val_loss: 0.6962 - val_mean_absolute_error: 0.5798\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.6340 - mean_absolute_error: 0.5477 - val_loss: 0.6607 - val_mean_absolute_error: 0.5606\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6220 - mean_absolute_error: 0.5419 - val_loss: 0.6738 - val_mean_absolute_error: 0.5648\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6371 - mean_absolute_error: 0.5563 - val_loss: 0.6942 - val_mean_absolute_error: 0.5757\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.6375 - mean_absolute_error: 0.5499 - val_loss: 0.6860 - val_mean_absolute_error: 0.6003\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.6423 - mean_absolute_error: 0.5713 - val_loss: 0.6950 - val_mean_absolute_error: 0.5794\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.6232 - mean_absolute_error: 0.5458 - val_loss: 0.6596 - val_mean_absolute_error: 0.5714\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.6312 - mean_absolute_error: 0.5485 - val_loss: 0.6725 - val_mean_absolute_error: 0.5738\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6063 - mean_absolute_error: 0.5373 - val_loss: 0.6677 - val_mean_absolute_error: 0.5847\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.6184 - mean_absolute_error: 0.5455 - val_loss: 0.7501 - val_mean_absolute_error: 0.6058\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6678 - mean_absolute_error: 0.5559 - val_loss: 0.6938 - val_mean_absolute_error: 0.6088\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6865 - mean_absolute_error: 0.5907 - val_loss: 0.6941 - val_mean_absolute_error: 0.5857\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.6209 - mean_absolute_error: 0.5539 - val_loss: 0.6597 - val_mean_absolute_error: 0.5776\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.6068 - mean_absolute_error: 0.5479 - val_loss: 0.6573 - val_mean_absolute_error: 0.5748\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.6163 - mean_absolute_error: 0.5539 - val_loss: 0.6803 - val_mean_absolute_error: 0.5783\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6248 - mean_absolute_error: 0.5466 - val_loss: 0.6518 - val_mean_absolute_error: 0.5729\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6500 - mean_absolute_error: 0.5792 - val_loss: 0.6725 - val_mean_absolute_error: 0.5875\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.6295 - mean_absolute_error: 0.5553 - val_loss: 0.6598 - val_mean_absolute_error: 0.5837\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6135 - mean_absolute_error: 0.5573 - val_loss: 0.6507 - val_mean_absolute_error: 0.5726\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.6018 - mean_absolute_error: 0.5419 - val_loss: 0.6630 - val_mean_absolute_error: 0.5723\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6107 - mean_absolute_error: 0.5487 - val_loss: 0.6473 - val_mean_absolute_error: 0.5673\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.6230 - mean_absolute_error: 0.5498 - val_loss: 0.6499 - val_mean_absolute_error: 0.5758\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.6145 - mean_absolute_error: 0.5558 - val_loss: 0.6485 - val_mean_absolute_error: 0.5765\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.5942 - mean_absolute_error: 0.5425 - val_loss: 0.6520 - val_mean_absolute_error: 0.5723\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.5880 - mean_absolute_error: 0.5396 - val_loss: 0.6373 - val_mean_absolute_error: 0.5667\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5932 - mean_absolute_error: 0.5401 - val_loss: 0.6413 - val_mean_absolute_error: 0.5673\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5877 - mean_absolute_error: 0.5398 - val_loss: 0.6437 - val_mean_absolute_error: 0.5744\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5879 - mean_absolute_error: 0.5440 - val_loss: 0.6528 - val_mean_absolute_error: 0.5801\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.5856 - mean_absolute_error: 0.5399 - val_loss: 0.6459 - val_mean_absolute_error: 0.5718\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5918 - mean_absolute_error: 0.5412 - val_loss: 0.6580 - val_mean_absolute_error: 0.5676\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.5883 - mean_absolute_error: 0.5370 - val_loss: 0.6419 - val_mean_absolute_error: 0.5779\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.5868 - mean_absolute_error: 0.5427 - val_loss: 0.6912 - val_mean_absolute_error: 0.5848\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.5982 - mean_absolute_error: 0.5354 - val_loss: 0.6543 - val_mean_absolute_error: 0.5860\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.6175 - mean_absolute_error: 0.5574 - val_loss: 0.6843 - val_mean_absolute_error: 0.5821\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6057 - mean_absolute_error: 0.5531 - val_loss: 0.6504 - val_mean_absolute_error: 0.5778\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.6207 - mean_absolute_error: 0.5510 - val_loss: 0.6556 - val_mean_absolute_error: 0.5879\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.5833 - mean_absolute_error: 0.5462 - val_loss: 0.6410 - val_mean_absolute_error: 0.5746\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.5815 - mean_absolute_error: 0.5424 - val_loss: 0.6627 - val_mean_absolute_error: 0.5751\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.6118 - mean_absolute_error: 0.5466 - val_loss: 0.6459 - val_mean_absolute_error: 0.5823\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6061 - mean_absolute_error: 0.5503 - val_loss: 0.6531 - val_mean_absolute_error: 0.5659\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.5867 - mean_absolute_error: 0.5368 - val_loss: 0.6334 - val_mean_absolute_error: 0.5720\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5966 - mean_absolute_error: 0.5466 - val_loss: 0.6544 - val_mean_absolute_error: 0.5721\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.5888 - mean_absolute_error: 0.5416 - val_loss: 0.6366 - val_mean_absolute_error: 0.5746\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5761 - mean_absolute_error: 0.5429 - val_loss: 0.6592 - val_mean_absolute_error: 0.5733\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.5876 - mean_absolute_error: 0.5392 - val_loss: 0.6267 - val_mean_absolute_error: 0.5671\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.5853 - mean_absolute_error: 0.5402 - val_loss: 0.6247 - val_mean_absolute_error: 0.5624\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mjpg_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'svg'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0msvg_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'pdf'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mpdf_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pdf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2057\u001b[0m         \"\"\"\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m_get_output_canvas\u001b[0;34m(self, fmt)\u001b[0m\n\u001b[1;32m   1991\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m             \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mget_registered_canvas_class\u001b[0;34m(format)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbackend\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcanvas\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mBackend\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhandling\u001b[0m \u001b[0mfile\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mdescription\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mDescription\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_svg.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont_manager\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m from matplotlib.backend_bases import (\n\u001b[0m\u001b[1;32m     19\u001b[0m      \u001b[0m_Backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_check_savefig_extra_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigureManagerBase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m      RendererBase)\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name '_check_savefig_extra_args' from 'matplotlib.backend_bases' (/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#### YOUR CODE HERE\n",
        "#Regularization\n",
        "from keras import regularizers\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu, input_shape=(10,), kernel_regularizer=regularizers.L2(0.01)),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu, kernel_regularizer = regularizers.L2(0.01)), \n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu, kernel_regularizer = regularizers.L2(0.01)), \n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu, kernel_regularizer = regularizers.L2(0.01)), \n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu, kernel_regularizer = regularizers.L2(0.01)),  \n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu, kernel_regularizer = regularizers.L2(0.01)), \n",
        "                                    tf.keras.layers.Dense(1)])\n",
        " ### START CODE HERE ### ()\n",
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'mean_squared_error',\n",
        "              metrics=['mean_absolute_error'])\n",
        "history = model.fit(train_data, train_targets,  batch_size = 64, epochs=100, validation_split = 0.15)\n",
        "\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss vs. epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39417149-9f72-4fde-945e-7ea7a649b01f",
      "metadata": {
        "id": "39417149-9f72-4fde-945e-7ea7a649b01f"
      },
      "source": [
        "# Part 3 Batches and Epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b167f30-1712-4875-8643-985d6bff5894",
      "metadata": {
        "id": "6b167f30-1712-4875-8643-985d6bff5894"
      },
      "source": [
        "In this part of the assignment we will create a synthetic data to play with. \n",
        "The data will have 2 features and 3 target classes --> multiclass classification problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "5478a898-76b8-4764-9194-54920d6889f8",
      "metadata": {
        "id": "5478a898-76b8-4764-9194-54920d6889f8"
      },
      "outputs": [],
      "source": [
        "# prepare train and test dataset\n",
        "def prepare_data():\n",
        "    #  generate classification dataset with 3 centers (labels/classes)\n",
        "    X, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
        "    \n",
        "    # plot data\n",
        "    for class_value in range(3):\n",
        "        # select indices of points with the class label\n",
        "        row_ix = np.where(y == class_value)\n",
        "        # scatter plot for points with a different color\n",
        "        plt.scatter(X[row_ix, 0], X[row_ix, 1])\n",
        "    # show plot\n",
        "    plt.show()\n",
        "\n",
        "    # one hot encode output variable to convert from integers to binary class\n",
        "    y = to_categorical(y)\n",
        "\n",
        "    # split into train and test\n",
        "    n_train = 500\n",
        "    X_train, X_test = X[:n_train, :], X[n_train:, :]\n",
        "    y_train, y_test = y[:n_train], y[n_train:]\n",
        "    return X_train, y_train, X_test, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "32e2cf07-c958-46c3-a453-f1bead3502b0",
      "metadata": {
        "id": "32e2cf07-c958-46c3-a453-f1bead3502b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "ec7318ac-7377-4487-cbbf-fa685c8528e8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mjpg_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'svg'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0msvg_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'pdf'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mpdf_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pdf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2057\u001b[0m         \"\"\"\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m_get_output_canvas\u001b[0;34m(self, fmt)\u001b[0m\n\u001b[1;32m   1991\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m             \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mget_registered_canvas_class\u001b[0;34m(format)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbackend\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcanvas\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mBackend\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhandling\u001b[0m \u001b[0mfile\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mdescription\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mDescription\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_svg.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont_manager\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m from matplotlib.backend_bases import (\n\u001b[0m\u001b[1;32m     19\u001b[0m      \u001b[0m_Backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_check_savefig_extra_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigureManagerBase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m      RendererBase)\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name '_check_savefig_extra_args' from 'matplotlib.backend_bases' (/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# prepare dataset\n",
        "X_train, y_train, X_test, y_test = prepare_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "780221cc-5e13-4fd9-a940-38d43232c17b",
      "metadata": {
        "id": "780221cc-5e13-4fd9-a940-38d43232c17b"
      },
      "source": [
        "- **Create a model with:**\n",
        "    -  1 hidden dense layer (50 neurons), activation relu, , kernel_initializer he_uniform\n",
        "    - 1 output layer\n",
        "    - compile the model with SGD (learning rate 0.01 and momentum 0.9) optimizer and categorical crossentropy and accuracy inside build function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "72840561-d883-4b04-85c0-aa3c25d88767",
      "metadata": {
        "id": "72840561-d883-4b04-85c0-aa3c25d88767"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    \n",
        "    ##### YOUR CODE HERE\n",
        " ### START CODE HERE ### ()\n",
        "     # define model\n",
        "    model = tf.keras.models.Sequential([\n",
        "                                  tf.keras.layers.Dense(50, activation=tf.nn.relu,  kernel_initializer  = tf.keras.initializers.HeUniform()),\n",
        "                                  tf.keras.layers.Dense(3)])\n",
        "    # compile model\n",
        "    model.compile(optimizer = tf.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
        "                  loss = 'categorical_crossentropy',\n",
        "                  metrics=['accuracy'])    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f77f064-219f-4130-95d6-6f55c500d8aa",
      "metadata": {
        "id": "9f77f064-219f-4130-95d6-6f55c500d8aa"
      },
      "source": [
        "- Create a function to fit and build the model with different batch sizes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36e5cb37-cf36-4f8f-9d2f-2adbeeea41bb",
      "metadata": {
        "id": "36e5cb37-cf36-4f8f-9d2f-2adbeeea41bb"
      },
      "source": [
        "Use epochs = 125"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "8b6d1185-925a-4a4e-9815-29a3ca1a62cf",
      "metadata": {
        "id": "8b6d1185-925a-4a4e-9815-29a3ca1a62cf"
      },
      "outputs": [],
      "source": [
        "# fit a model and plot learning curve\n",
        "def fit_model(X_train, y_train, X_test, y_test, n_batch):\n",
        "    ##### YOUR CODE HERE\n",
        "    # build model\n",
        "    model = build_model()\n",
        "    # fit model\n",
        "    history = model.fit(X_train, y_train,  batch_size = n_batch, epochs=125, validation_split = 0.15)\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2539b4f-8829-4df1-9a45-a9c438a37baf",
      "metadata": {
        "id": "b2539b4f-8829-4df1-9a45-a9c438a37baf"
      },
      "source": [
        "### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb875222-fd78-4ed5-a33f-a9c085bd5534",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "fb875222-fd78-4ed5-a33f-a9c085bd5534"
      },
      "source": [
        "#### Batch size"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c2c8424-0b59-45be-8bc3-0f310fb8ed30",
      "metadata": {
        "id": "3c2c8424-0b59-45be-8bc3-0f310fb8ed30"
      },
      "source": [
        "##### Size =  1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77369330-70e7-41eb-a8ff-40eae827ea7d",
      "metadata": {
        "id": "77369330-70e7-41eb-a8ff-40eae827ea7d"
      },
      "source": [
        "10. **train for 1 batch size**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "a44f1126-7897-4cd8-bdce-b804948df69d",
      "metadata": {
        "id": "a44f1126-7897-4cd8-bdce-b804948df69d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76f4e606-364c-440d-8135-89e1d1f228ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.3446 - accuracy: 0.3412 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 2/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 3/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 4/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 5/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 6/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 7/125\n",
            "425/425 [==============================] - 1s 3ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 8/125\n",
            "425/425 [==============================] - 1s 3ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 9/125\n",
            "425/425 [==============================] - 1s 3ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 10/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 11/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 12/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 13/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 14/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 15/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 16/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 17/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 18/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 19/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 20/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 21/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 22/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 23/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 24/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 25/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 26/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 27/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 28/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 29/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 30/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 31/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 32/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 33/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 34/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 35/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 36/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 37/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 38/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 39/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 40/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 41/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 42/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 43/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 44/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 45/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 46/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 47/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 48/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 49/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 50/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 51/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 52/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 53/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 54/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 55/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 56/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 57/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 58/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 59/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 60/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 61/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 62/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 63/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 64/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 65/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 66/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 67/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 68/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 69/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 70/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 71/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 72/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 73/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 74/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 75/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 76/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 77/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 78/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 79/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 80/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 81/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 82/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 83/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 84/125\n",
            "425/425 [==============================] - 1s 3ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 85/125\n",
            "425/425 [==============================] - 2s 4ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 86/125\n",
            "425/425 [==============================] - 1s 3ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 87/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 88/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 89/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 90/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 91/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 92/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 93/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 94/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 95/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 96/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 97/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 98/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 99/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 100/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 101/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 102/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 103/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 104/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 105/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 106/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 107/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 108/125\n",
            "425/425 [==============================] - 1s 3ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 109/125\n",
            "425/425 [==============================] - 1s 3ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 110/125\n",
            "425/425 [==============================] - 1s 3ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 111/125\n",
            "425/425 [==============================] - 1s 3ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 112/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 113/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 114/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 115/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 116/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 117/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 118/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 119/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 120/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 121/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 122/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 123/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 124/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n",
            "Epoch 125/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.4472 - accuracy: 0.3318 - val_loss: 6.8771 - val_accuracy: 0.3467\n"
          ]
        }
      ],
      "source": [
        "### START CODE HERE ### \n",
        "batch_size = 1\n",
        "history = fit_model(X_train, y_train, X_test, y_test, batch_size)\n",
        "###### END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "022e2c92-7a62-49f9-aae2-790c5eae36e4",
      "metadata": {
        "tags": [],
        "id": "022e2c92-7a62-49f9-aae2-790c5eae36e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "9b948c27-f6c3-4253-e421-25c7597c9150"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mjpg_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'svg'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0msvg_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'pdf'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mpdf_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pdf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2057\u001b[0m         \"\"\"\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m_get_output_canvas\u001b[0;34m(self, fmt)\u001b[0m\n\u001b[1;32m   1991\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m             \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mget_registered_canvas_class\u001b[0;34m(format)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbackend\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcanvas\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mBackend\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhandling\u001b[0m \u001b[0mfile\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mdescription\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mDescription\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_svg.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont_manager\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m from matplotlib.backend_bases import (\n\u001b[0m\u001b[1;32m     19\u001b[0m      \u001b[0m_Backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_check_savefig_extra_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigureManagerBase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m      RendererBase)\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name '_check_savefig_extra_args' from 'matplotlib.backend_bases' (/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss vs. epochs, batch=' +str(batch_size))\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "058a1cdc-e6ec-4fca-b87f-29a161f9986d",
      "metadata": {
        "id": "058a1cdc-e6ec-4fca-b87f-29a161f9986d"
      },
      "source": [
        "- **Diagnose this curve w.r.t learning rate**:\n",
        "    - ANSWER: learning rate is big\n",
        "- Change learning rate to make this curve better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "74b641cb-d7b1-4806-a4f9-216006e06e77",
      "metadata": {
        "id": "74b641cb-d7b1-4806-a4f9-216006e06e77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ade907bc-14db-4994-a375-1dd9b6327e66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 2) (500, 3)\n",
            "Epoch 1/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 6.0592 - accuracy: 0.3035 - val_loss: 1.9539 - val_accuracy: 0.2000\n",
            "Epoch 2/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 4.1362 - accuracy: 0.1859 - val_loss: 7.5445 - val_accuracy: 0.3200\n",
            "Epoch 3/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 5.8045 - accuracy: 0.3129 - val_loss: 7.0260 - val_accuracy: 0.3333\n",
            "Epoch 4/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 5.5849 - accuracy: 0.3106 - val_loss: 7.1786 - val_accuracy: 0.3333\n",
            "Epoch 5/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 5.4947 - accuracy: 0.3082 - val_loss: 7.1200 - val_accuracy: 0.3200\n",
            "Epoch 6/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 5.5703 - accuracy: 0.3082 - val_loss: 7.1168 - val_accuracy: 0.3200\n",
            "Epoch 7/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 4.1556 - accuracy: 0.2518 - val_loss: 0.8689 - val_accuracy: 0.1067\n",
            "Epoch 8/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 0.7083 - accuracy: 0.0729 - val_loss: 0.3663 - val_accuracy: 0.0133\n",
            "Epoch 9/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 2.6479 - accuracy: 0.0071 - val_loss: 8.6742 - val_accuracy: 0.0133\n",
            "Epoch 10/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 1.6411 - accuracy: 0.3082 - val_loss: 2.1877 - val_accuracy: 0.4133\n",
            "Epoch 11/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 1.8777 - accuracy: 0.3294 - val_loss: 2.1754 - val_accuracy: 0.4133\n",
            "Epoch 12/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 1.9862 - accuracy: 0.3294 - val_loss: 2.5988 - val_accuracy: 0.4133\n",
            "Epoch 13/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 2.0589 - accuracy: 0.3294 - val_loss: 2.3794 - val_accuracy: 0.4133\n",
            "Epoch 14/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 2.1321 - accuracy: 0.3294 - val_loss: 2.3755 - val_accuracy: 0.4133\n",
            "Epoch 15/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 2.5091 - accuracy: 0.3294 - val_loss: 2.3723 - val_accuracy: 0.4133\n",
            "Epoch 16/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 2.6587 - accuracy: 0.3294 - val_loss: 2.3696 - val_accuracy: 0.4133\n",
            "Epoch 17/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 2.9600 - accuracy: 0.3294 - val_loss: 2.3673 - val_accuracy: 0.4133\n",
            "Epoch 18/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.0348 - accuracy: 0.3294 - val_loss: 2.5811 - val_accuracy: 0.4133\n",
            "Epoch 19/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.2620 - accuracy: 0.3294 - val_loss: 2.5806 - val_accuracy: 0.4133\n",
            "Epoch 20/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.4893 - accuracy: 0.3294 - val_loss: 2.5800 - val_accuracy: 0.4133\n",
            "Epoch 21/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.5651 - accuracy: 0.3294 - val_loss: 2.5797 - val_accuracy: 0.4133\n",
            "Epoch 22/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7167 - accuracy: 0.3294 - val_loss: 2.5794 - val_accuracy: 0.4133\n",
            "Epoch 23/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7167 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 24/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 25/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 26/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 27/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 28/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 29/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 30/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 31/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 32/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 33/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 34/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 35/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 36/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 37/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 38/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 39/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 40/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 41/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 42/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 43/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 44/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 45/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 46/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 47/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 48/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 49/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 50/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 51/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 52/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 53/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 54/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 55/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 56/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 57/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 58/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 59/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 60/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 61/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 62/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 63/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 64/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 65/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 66/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 67/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 68/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 69/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 70/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 71/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 72/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 73/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 74/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 75/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 76/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 77/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 78/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 79/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 80/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 81/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 82/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 83/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 84/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 85/125\n",
            "425/425 [==============================] - 1s 3ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 86/125\n",
            "425/425 [==============================] - 1s 3ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 87/125\n",
            "425/425 [==============================] - 1s 3ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 88/125\n",
            "425/425 [==============================] - 1s 3ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 89/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 90/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 91/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 92/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 93/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 94/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 95/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 96/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 97/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 98/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 99/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 100/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 101/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 102/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 103/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 104/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 105/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 106/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 107/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 108/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 109/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 110/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 111/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 112/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 113/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 114/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 115/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 116/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 117/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 118/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 119/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 120/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 121/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 122/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 123/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 124/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n",
            "Epoch 125/125\n",
            "425/425 [==============================] - 1s 2ms/step - loss: 3.7546 - accuracy: 0.3294 - val_loss: 2.7942 - val_accuracy: 0.4133\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mjpg_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'svg'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0msvg_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'pdf'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mpdf_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pdf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2057\u001b[0m         \"\"\"\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m_get_output_canvas\u001b[0;34m(self, fmt)\u001b[0m\n\u001b[1;32m   1991\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m             \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mget_registered_canvas_class\u001b[0;34m(format)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbackend\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcanvas\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mBackend\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhandling\u001b[0m \u001b[0mfile\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mdescription\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mDescription\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_svg.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont_manager\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m from matplotlib.backend_bases import (\n\u001b[0m\u001b[1;32m     19\u001b[0m      \u001b[0m_Backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_check_savefig_extra_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigureManagerBase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m      RendererBase)\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name '_check_savefig_extra_args' from 'matplotlib.backend_bases' (/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "### Your answer\n",
        "# define model\n",
        "model = tf.keras.models.Sequential([\n",
        "                              tf.keras.layers.Dense(50, activation=tf.nn.relu,  kernel_initializer  = tf.keras.initializers.HeUniform()),\n",
        "                              tf.keras.layers.Dense(3)])\n",
        "# compile model\n",
        "model.compile(optimizer = tf.optimizers.SGD(learning_rate=0.0001, momentum=0.9),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics=['accuracy'])    \n",
        "# build model\n",
        "print(X_train.shape, y_train.shape)\n",
        "model = build_model()\n",
        "# fit model\n",
        "history = model.fit(X_train, y_train, batch_size = 1, epochs=125, validation_split = 0.15)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss vs. epochs, batch=' +str(batch_size))\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca24463c-6d6d-4dce-b365-1e0a10cbb6b9",
      "metadata": {
        "tags": [],
        "id": "ca24463c-6d6d-4dce-b365-1e0a10cbb6b9"
      },
      "source": [
        "##### Size =  16"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9d3f83a-edf8-4f61-a0fe-db3261ace6ab",
      "metadata": {
        "id": "c9d3f83a-edf8-4f61-a0fe-db3261ace6ab"
      },
      "source": [
        "10. **Retrain for 16 batch size**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "589fd6d3-6c4d-48ed-b5db-9e3d931725d0",
      "metadata": {
        "id": "589fd6d3-6c4d-48ed-b5db-9e3d931725d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4638c6c9-a538-4edf-95b8-54defc600afa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/125\n",
            "27/27 [==============================] - 1s 8ms/step - loss: 5.7278 - accuracy: 0.4047 - val_loss: 7.1806 - val_accuracy: 0.3467\n",
            "Epoch 2/125\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5.4916 - accuracy: 0.4471 - val_loss: 6.8104 - val_accuracy: 0.3600\n",
            "Epoch 3/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.0890 - accuracy: 0.4612 - val_loss: 8.0527 - val_accuracy: 0.3867\n",
            "Epoch 4/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.4346 - accuracy: 0.4706 - val_loss: 8.6794 - val_accuracy: 0.4400\n",
            "Epoch 5/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.9587 - accuracy: 0.4706 - val_loss: 8.8848 - val_accuracy: 0.4267\n",
            "Epoch 6/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.8786 - accuracy: 0.4800 - val_loss: 8.2346 - val_accuracy: 0.4133\n",
            "Epoch 7/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.6479 - accuracy: 0.4847 - val_loss: 7.8009 - val_accuracy: 0.4267\n",
            "Epoch 8/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.8731 - accuracy: 0.4988 - val_loss: 7.7984 - val_accuracy: 0.4267\n",
            "Epoch 9/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.7577 - accuracy: 0.5082 - val_loss: 8.0112 - val_accuracy: 0.4400\n",
            "Epoch 10/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.6803 - accuracy: 0.5082 - val_loss: 7.7948 - val_accuracy: 0.4400\n",
            "Epoch 11/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.7549 - accuracy: 0.5035 - val_loss: 7.7931 - val_accuracy: 0.4267\n",
            "Epoch 12/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.4125 - accuracy: 0.5035 - val_loss: 7.1469 - val_accuracy: 0.4267\n",
            "Epoch 13/125\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 7.3356 - accuracy: 0.5035 - val_loss: 6.9307 - val_accuracy: 0.4400\n",
            "Epoch 14/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.4105 - accuracy: 0.5082 - val_loss: 6.9296 - val_accuracy: 0.4533\n",
            "Epoch 15/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.4475 - accuracy: 0.5082 - val_loss: 6.7136 - val_accuracy: 0.4533\n",
            "Epoch 16/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.4846 - accuracy: 0.5106 - val_loss: 6.2828 - val_accuracy: 0.4533\n",
            "Epoch 17/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.3323 - accuracy: 0.5082 - val_loss: 6.7115 - val_accuracy: 0.4667\n",
            "Epoch 18/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.2559 - accuracy: 0.5082 - val_loss: 6.7107 - val_accuracy: 0.4667\n",
            "Epoch 19/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.2175 - accuracy: 0.5106 - val_loss: 6.9249 - val_accuracy: 0.4667\n",
            "Epoch 20/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.2171 - accuracy: 0.5106 - val_loss: 6.4942 - val_accuracy: 0.4667\n",
            "Epoch 21/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.1787 - accuracy: 0.5082 - val_loss: 6.2786 - val_accuracy: 0.4667\n",
            "Epoch 22/125\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 7.2162 - accuracy: 0.5082 - val_loss: 6.2779 - val_accuracy: 0.4667\n",
            "Epoch 23/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.0261 - accuracy: 0.5082 - val_loss: 6.4921 - val_accuracy: 0.4667\n",
            "Epoch 24/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.8740 - accuracy: 0.5082 - val_loss: 6.4914 - val_accuracy: 0.4667\n",
            "Epoch 25/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.8736 - accuracy: 0.5035 - val_loss: 6.2759 - val_accuracy: 0.4667\n",
            "Epoch 26/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.8352 - accuracy: 0.5035 - val_loss: 6.0603 - val_accuracy: 0.4667\n",
            "Epoch 27/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.8348 - accuracy: 0.5012 - val_loss: 6.0598 - val_accuracy: 0.4667\n",
            "Epoch 28/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.9102 - accuracy: 0.4988 - val_loss: 6.2741 - val_accuracy: 0.4667\n",
            "Epoch 29/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.7960 - accuracy: 0.4965 - val_loss: 6.2735 - val_accuracy: 0.4667\n",
            "Epoch 30/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.7196 - accuracy: 0.4941 - val_loss: 6.4878 - val_accuracy: 0.4667\n",
            "Epoch 31/125\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5.9965 - accuracy: 0.4800 - val_loss: 5.4500 - val_accuracy: 0.4533\n",
            "Epoch 32/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.3975 - accuracy: 0.4329 - val_loss: 5.2798 - val_accuracy: 0.4267\n",
            "Epoch 33/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.0922 - accuracy: 0.4188 - val_loss: 5.2430 - val_accuracy: 0.4267\n",
            "Epoch 34/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.2429 - accuracy: 0.4306 - val_loss: 6.7070 - val_accuracy: 0.4667\n",
            "Epoch 35/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.9277 - accuracy: 0.4965 - val_loss: 7.7807 - val_accuracy: 0.4667\n",
            "Epoch 36/125\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6.8464 - accuracy: 0.4918 - val_loss: 7.7812 - val_accuracy: 0.4400\n",
            "Epoch 37/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.8069 - accuracy: 0.4965 - val_loss: 7.7797 - val_accuracy: 0.4667\n",
            "Epoch 38/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.9941 - accuracy: 0.4941 - val_loss: 7.7789 - val_accuracy: 0.4667\n",
            "Epoch 39/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.9554 - accuracy: 0.4965 - val_loss: 7.7783 - val_accuracy: 0.4667\n",
            "Epoch 40/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.9169 - accuracy: 0.4941 - val_loss: 7.7775 - val_accuracy: 0.4667\n",
            "Epoch 41/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.8404 - accuracy: 0.4941 - val_loss: 7.7769 - val_accuracy: 0.4800\n",
            "Epoch 42/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.7639 - accuracy: 0.4965 - val_loss: 7.7763 - val_accuracy: 0.4800\n",
            "Epoch 43/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.8392 - accuracy: 0.4988 - val_loss: 7.3459 - val_accuracy: 0.4800\n",
            "Epoch 44/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.9145 - accuracy: 0.4941 - val_loss: 7.3453 - val_accuracy: 0.4800\n",
            "Epoch 45/125\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5.8976 - accuracy: 0.4047 - val_loss: 6.3029 - val_accuracy: 0.3600\n",
            "Epoch 46/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.7786 - accuracy: 0.3576 - val_loss: 6.8800 - val_accuracy: 0.3333\n",
            "Epoch 47/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.7691 - accuracy: 0.3506 - val_loss: 6.8270 - val_accuracy: 0.3333\n",
            "Epoch 48/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.7352 - accuracy: 0.3506 - val_loss: 6.7878 - val_accuracy: 0.3333\n",
            "Epoch 49/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.6329 - accuracy: 0.3506 - val_loss: 6.5417 - val_accuracy: 0.3333\n",
            "Epoch 50/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.6110 - accuracy: 0.3506 - val_loss: 6.5152 - val_accuracy: 0.3333\n",
            "Epoch 51/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.5919 - accuracy: 0.3506 - val_loss: 6.4934 - val_accuracy: 0.3467\n",
            "Epoch 52/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.4241 - accuracy: 0.3506 - val_loss: 6.4720 - val_accuracy: 0.3467\n",
            "Epoch 53/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.3711 - accuracy: 0.3506 - val_loss: 6.0230 - val_accuracy: 0.3467\n",
            "Epoch 54/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.3196 - accuracy: 0.3506 - val_loss: 6.0055 - val_accuracy: 0.3467\n",
            "Epoch 55/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.1554 - accuracy: 0.3459 - val_loss: 5.9906 - val_accuracy: 0.3467\n",
            "Epoch 56/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.0682 - accuracy: 0.3459 - val_loss: 5.9761 - val_accuracy: 0.3467\n",
            "Epoch 57/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.0574 - accuracy: 0.3459 - val_loss: 5.9633 - val_accuracy: 0.3467\n",
            "Epoch 58/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.0097 - accuracy: 0.3435 - val_loss: 5.9510 - val_accuracy: 0.3467\n",
            "Epoch 59/125\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6.0004 - accuracy: 0.3435 - val_loss: 5.9401 - val_accuracy: 0.3467\n",
            "Epoch 60/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.9917 - accuracy: 0.3435 - val_loss: 5.9297 - val_accuracy: 0.3467\n",
            "Epoch 61/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.9833 - accuracy: 0.3435 - val_loss: 5.9195 - val_accuracy: 0.3467\n",
            "Epoch 62/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.9752 - accuracy: 0.3435 - val_loss: 5.9098 - val_accuracy: 0.3467\n",
            "Epoch 63/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.9674 - accuracy: 0.3435 - val_loss: 5.9011 - val_accuracy: 0.3467\n",
            "Epoch 64/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.9602 - accuracy: 0.3435 - val_loss: 5.8913 - val_accuracy: 0.3467\n",
            "Epoch 65/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.9526 - accuracy: 0.3435 - val_loss: 5.8822 - val_accuracy: 0.3467\n",
            "Epoch 66/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.9836 - accuracy: 0.3435 - val_loss: 5.8736 - val_accuracy: 0.3467\n",
            "Epoch 67/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.9387 - accuracy: 0.3435 - val_loss: 5.8655 - val_accuracy: 0.3467\n",
            "Epoch 68/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.9700 - accuracy: 0.3435 - val_loss: 5.8564 - val_accuracy: 0.3467\n",
            "Epoch 69/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.9632 - accuracy: 0.3435 - val_loss: 5.8487 - val_accuracy: 0.3467\n",
            "Epoch 70/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.9567 - accuracy: 0.3435 - val_loss: 5.8405 - val_accuracy: 0.3467\n",
            "Epoch 71/125\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5.9503 - accuracy: 0.3435 - val_loss: 5.8331 - val_accuracy: 0.3467\n",
            "Epoch 72/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.9819 - accuracy: 0.3435 - val_loss: 5.8257 - val_accuracy: 0.3467\n",
            "Epoch 73/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.0137 - accuracy: 0.3435 - val_loss: 5.8181 - val_accuracy: 0.3467\n",
            "Epoch 74/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.0454 - accuracy: 0.3435 - val_loss: 5.8108 - val_accuracy: 0.3467\n",
            "Epoch 75/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.0394 - accuracy: 0.3435 - val_loss: 5.8035 - val_accuracy: 0.3467\n",
            "Epoch 76/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.0333 - accuracy: 0.3435 - val_loss: 6.0106 - val_accuracy: 0.3467\n",
            "Epoch 77/125\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6.0272 - accuracy: 0.3435 - val_loss: 6.0039 - val_accuracy: 0.3467\n",
            "Epoch 78/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.0213 - accuracy: 0.3435 - val_loss: 5.9965 - val_accuracy: 0.3467\n",
            "Epoch 79/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.0154 - accuracy: 0.3435 - val_loss: 5.9895 - val_accuracy: 0.3467\n",
            "Epoch 80/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.0093 - accuracy: 0.3435 - val_loss: 5.9829 - val_accuracy: 0.3467\n",
            "Epoch 81/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.0034 - accuracy: 0.3435 - val_loss: 5.9754 - val_accuracy: 0.3467\n",
            "Epoch 82/125\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 6.0354 - accuracy: 0.3435 - val_loss: 5.9684 - val_accuracy: 0.3467\n",
            "Epoch 83/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.0293 - accuracy: 0.3435 - val_loss: 5.9618 - val_accuracy: 0.3467\n",
            "Epoch 84/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.0614 - accuracy: 0.3435 - val_loss: 5.9545 - val_accuracy: 0.3467\n",
            "Epoch 85/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.0554 - accuracy: 0.3435 - val_loss: 5.9476 - val_accuracy: 0.3467\n",
            "Epoch 86/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.0495 - accuracy: 0.3435 - val_loss: 5.9410 - val_accuracy: 0.3467\n",
            "Epoch 87/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.0514 - accuracy: 0.3482 - val_loss: 5.7355 - val_accuracy: 0.3600\n",
            "Epoch 88/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.9689 - accuracy: 0.3788 - val_loss: 5.7280 - val_accuracy: 0.4267\n",
            "Epoch 89/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.9265 - accuracy: 0.4024 - val_loss: 5.7197 - val_accuracy: 0.4267\n",
            "Epoch 90/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.8413 - accuracy: 0.4118 - val_loss: 5.7110 - val_accuracy: 0.4267\n",
            "Epoch 91/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.8692 - accuracy: 0.4118 - val_loss: 5.9181 - val_accuracy: 0.4267\n",
            "Epoch 92/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.8618 - accuracy: 0.4118 - val_loss: 5.9101 - val_accuracy: 0.4267\n",
            "Epoch 93/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.9303 - accuracy: 0.4141 - val_loss: 5.9028 - val_accuracy: 0.4267\n",
            "Epoch 94/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.8853 - accuracy: 0.4141 - val_loss: 5.6993 - val_accuracy: 0.4267\n",
            "Epoch 95/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.7385 - accuracy: 0.4212 - val_loss: 5.6713 - val_accuracy: 0.4400\n",
            "Epoch 96/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.6397 - accuracy: 0.4353 - val_loss: 5.6582 - val_accuracy: 0.4400\n",
            "Epoch 97/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.7069 - accuracy: 0.4329 - val_loss: 5.6496 - val_accuracy: 0.4400\n",
            "Epoch 98/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.6611 - accuracy: 0.4329 - val_loss: 5.6403 - val_accuracy: 0.4400\n",
            "Epoch 99/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.6535 - accuracy: 0.4353 - val_loss: 5.6309 - val_accuracy: 0.4400\n",
            "Epoch 100/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.5730 - accuracy: 0.4353 - val_loss: 5.6108 - val_accuracy: 0.4533\n",
            "Epoch 101/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.5684 - accuracy: 0.4329 - val_loss: 5.6224 - val_accuracy: 0.4400\n",
            "Epoch 102/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.7197 - accuracy: 0.4212 - val_loss: 5.6234 - val_accuracy: 0.4267\n",
            "Epoch 103/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.7166 - accuracy: 0.4212 - val_loss: 5.6162 - val_accuracy: 0.4267\n",
            "Epoch 104/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.7112 - accuracy: 0.4212 - val_loss: 5.6085 - val_accuracy: 0.4267\n",
            "Epoch 105/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.7487 - accuracy: 0.4141 - val_loss: 5.6038 - val_accuracy: 0.4267\n",
            "Epoch 106/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.8200 - accuracy: 0.4141 - val_loss: 5.5965 - val_accuracy: 0.4267\n",
            "Epoch 107/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.8509 - accuracy: 0.4141 - val_loss: 5.5888 - val_accuracy: 0.4267\n",
            "Epoch 108/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.8444 - accuracy: 0.4141 - val_loss: 5.5805 - val_accuracy: 0.4267\n",
            "Epoch 109/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.8381 - accuracy: 0.4118 - val_loss: 5.5723 - val_accuracy: 0.4267\n",
            "Epoch 110/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.8317 - accuracy: 0.4118 - val_loss: 5.5642 - val_accuracy: 0.4267\n",
            "Epoch 111/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.8253 - accuracy: 0.4118 - val_loss: 5.7709 - val_accuracy: 0.4267\n",
            "Epoch 112/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.8188 - accuracy: 0.4118 - val_loss: 5.7623 - val_accuracy: 0.4267\n",
            "Epoch 113/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.8122 - accuracy: 0.4118 - val_loss: 5.7538 - val_accuracy: 0.4267\n",
            "Epoch 114/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.8055 - accuracy: 0.4118 - val_loss: 5.7448 - val_accuracy: 0.4267\n",
            "Epoch 115/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.7986 - accuracy: 0.4118 - val_loss: 5.7357 - val_accuracy: 0.4267\n",
            "Epoch 116/125\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 5.8672 - accuracy: 0.4141 - val_loss: 5.9412 - val_accuracy: 0.4267\n",
            "Epoch 117/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.8229 - accuracy: 0.4141 - val_loss: 5.7192 - val_accuracy: 0.4267\n",
            "Epoch 118/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.7385 - accuracy: 0.4141 - val_loss: 5.7065 - val_accuracy: 0.4267\n",
            "Epoch 119/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.7680 - accuracy: 0.4141 - val_loss: 5.6961 - val_accuracy: 0.4267\n",
            "Epoch 120/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.7595 - accuracy: 0.4118 - val_loss: 5.6859 - val_accuracy: 0.4267\n",
            "Epoch 121/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.7575 - accuracy: 0.4141 - val_loss: 5.6719 - val_accuracy: 0.4267\n",
            "Epoch 122/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.6239 - accuracy: 0.4212 - val_loss: 5.6623 - val_accuracy: 0.4267\n",
            "Epoch 123/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.5773 - accuracy: 0.4212 - val_loss: 5.6517 - val_accuracy: 0.4267\n",
            "Epoch 124/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.5692 - accuracy: 0.4212 - val_loss: 5.6423 - val_accuracy: 0.4267\n",
            "Epoch 125/125\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.6002 - accuracy: 0.4212 - val_loss: 5.6334 - val_accuracy: 0.4267\n"
          ]
        }
      ],
      "source": [
        "### START CODE HERE ### \n",
        "batch_size = 16\n",
        "history = fit_model(X_train, y_train, X_test, y_test, batch_size)\n",
        "###### END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "be8533d7-34a0-4072-a9f3-600ddb9e58df",
      "metadata": {
        "tags": [],
        "id": "be8533d7-34a0-4072-a9f3-600ddb9e58df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "9eb86b50-09fc-4c3d-f548-60888500ff62"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mjpg_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'svg'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0msvg_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'pdf'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mpdf_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pdf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2057\u001b[0m         \"\"\"\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m_get_output_canvas\u001b[0;34m(self, fmt)\u001b[0m\n\u001b[1;32m   1991\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m             \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mget_registered_canvas_class\u001b[0;34m(format)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbackend\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcanvas\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mBackend\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhandling\u001b[0m \u001b[0mfile\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mdescription\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mDescription\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_svg.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont_manager\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m from matplotlib.backend_bases import (\n\u001b[0m\u001b[1;32m     19\u001b[0m      \u001b[0m_Backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_check_savefig_extra_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigureManagerBase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m      RendererBase)\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name '_check_savefig_extra_args' from 'matplotlib.backend_bases' (/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss vs. epochs, batch=' +str(batch_size))\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7c4cd41-4aa3-4a8e-a6bb-3c7862c25787",
      "metadata": {
        "id": "a7c4cd41-4aa3-4a8e-a6bb-3c7862c25787"
      },
      "source": [
        "##### Size =  128"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55ae315d-ccfd-42aa-9e02-b2ba042756ec",
      "metadata": {
        "id": "55ae315d-ccfd-42aa-9e02-b2ba042756ec"
      },
      "source": [
        "10. **Retrain for 128 batch size**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "220b57cc-c220-424f-b3df-25eff109f718",
      "metadata": {
        "id": "220b57cc-c220-424f-b3df-25eff109f718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5e647d34-445a-48d2-fc9a-393b39ede473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/125\n",
            "4/4 [==============================] - 1s 54ms/step - loss: 1.4891 - accuracy: 0.3882 - val_loss: 0.9822 - val_accuracy: 0.5600\n",
            "Epoch 2/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0582 - accuracy: 0.5082 - val_loss: 1.0279 - val_accuracy: 0.3867\n",
            "Epoch 3/125\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.1443 - accuracy: 0.4000 - val_loss: 1.0387 - val_accuracy: 0.3333\n",
            "Epoch 4/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1851 - accuracy: 0.3953 - val_loss: 0.9870 - val_accuracy: 0.3333\n",
            "Epoch 5/125\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.1863 - accuracy: 0.4118 - val_loss: 0.9323 - val_accuracy: 0.3733\n",
            "Epoch 6/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2746 - accuracy: 0.4329 - val_loss: 0.8823 - val_accuracy: 0.5467\n",
            "Epoch 7/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.2187 - accuracy: 0.5506 - val_loss: 0.8445 - val_accuracy: 0.6000\n",
            "Epoch 8/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0747 - accuracy: 0.5694 - val_loss: 1.2954 - val_accuracy: 0.6533\n",
            "Epoch 9/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0935 - accuracy: 0.5506 - val_loss: 1.2589 - val_accuracy: 0.6533\n",
            "Epoch 10/125\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0457 - accuracy: 0.5459 - val_loss: 1.6731 - val_accuracy: 0.6800\n",
            "Epoch 11/125\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.1818 - accuracy: 0.5506 - val_loss: 1.6626 - val_accuracy: 0.6933\n",
            "Epoch 12/125\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.1679 - accuracy: 0.5765 - val_loss: 1.6517 - val_accuracy: 0.6133\n",
            "Epoch 13/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1388 - accuracy: 0.5529 - val_loss: 2.0718 - val_accuracy: 0.4400\n",
            "Epoch 14/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1937 - accuracy: 0.4376 - val_loss: 2.2592 - val_accuracy: 0.4533\n",
            "Epoch 15/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.5322 - accuracy: 0.5718 - val_loss: 2.1305 - val_accuracy: 0.5867\n",
            "Epoch 16/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 4.5518 - accuracy: 0.4565 - val_loss: 9.4824 - val_accuracy: 0.5867\n",
            "Epoch 17/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 8.6535 - accuracy: 0.4706 - val_loss: 10.7545 - val_accuracy: 0.5867\n",
            "Epoch 18/125\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 9.7343 - accuracy: 0.5224 - val_loss: 10.9673 - val_accuracy: 0.4133\n",
            "Epoch 19/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 10.1040 - accuracy: 0.3506 - val_loss: 11.3954 - val_accuracy: 0.3467\n",
            "Epoch 20/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 10.1782 - accuracy: 0.3318 - val_loss: 11.3940 - val_accuracy: 0.3467\n",
            "Epoch 21/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 10.2679 - accuracy: 0.3318 - val_loss: 9.3785 - val_accuracy: 0.3467\n",
            "Epoch 22/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 6.9168 - accuracy: 0.3318 - val_loss: 6.1901 - val_accuracy: 0.3467\n",
            "Epoch 23/125\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 6.1625 - accuracy: 0.3318 - val_loss: 6.1189 - val_accuracy: 0.3467\n",
            "Epoch 24/125\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 6.1424 - accuracy: 0.3318 - val_loss: 6.0944 - val_accuracy: 0.3467\n",
            "Epoch 25/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 6.1379 - accuracy: 0.3318 - val_loss: 6.0807 - val_accuracy: 0.3467\n",
            "Epoch 26/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 6.1320 - accuracy: 0.3318 - val_loss: 6.0711 - val_accuracy: 0.3467\n",
            "Epoch 27/125\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 6.1259 - accuracy: 0.3318 - val_loss: 6.0628 - val_accuracy: 0.3467\n",
            "Epoch 28/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 6.1193 - accuracy: 0.3318 - val_loss: 6.0550 - val_accuracy: 0.3467\n",
            "Epoch 29/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 6.1122 - accuracy: 0.3318 - val_loss: 6.0474 - val_accuracy: 0.3467\n",
            "Epoch 30/125\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 6.0451 - accuracy: 0.3318 - val_loss: 6.0401 - val_accuracy: 0.3467\n",
            "Epoch 31/125\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 5.9642 - accuracy: 0.3318 - val_loss: 5.8592 - val_accuracy: 0.3467\n",
            "Epoch 32/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.7627 - accuracy: 0.3318 - val_loss: 5.8393 - val_accuracy: 0.3467\n",
            "Epoch 33/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.6643 - accuracy: 0.3318 - val_loss: 5.8273 - val_accuracy: 0.3467\n",
            "Epoch 34/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.6447 - accuracy: 0.3318 - val_loss: 5.8172 - val_accuracy: 0.3467\n",
            "Epoch 35/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.6307 - accuracy: 0.3318 - val_loss: 5.8075 - val_accuracy: 0.3467\n",
            "Epoch 36/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.6176 - accuracy: 0.3318 - val_loss: 5.7976 - val_accuracy: 0.3467\n",
            "Epoch 37/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.6054 - accuracy: 0.3318 - val_loss: 5.7873 - val_accuracy: 0.3467\n",
            "Epoch 38/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.5932 - accuracy: 0.3318 - val_loss: 5.7765 - val_accuracy: 0.3467\n",
            "Epoch 39/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.5814 - accuracy: 0.3318 - val_loss: 5.7648 - val_accuracy: 0.3467\n",
            "Epoch 40/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.5688 - accuracy: 0.3318 - val_loss: 5.7527 - val_accuracy: 0.3467\n",
            "Epoch 41/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.5562 - accuracy: 0.3318 - val_loss: 5.7401 - val_accuracy: 0.3467\n",
            "Epoch 42/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.5433 - accuracy: 0.3318 - val_loss: 5.7275 - val_accuracy: 0.3467\n",
            "Epoch 43/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.5304 - accuracy: 0.3318 - val_loss: 5.7153 - val_accuracy: 0.3467\n",
            "Epoch 44/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.5173 - accuracy: 0.3318 - val_loss: 5.7035 - val_accuracy: 0.3467\n",
            "Epoch 45/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.5047 - accuracy: 0.3318 - val_loss: 5.6922 - val_accuracy: 0.3467\n",
            "Epoch 46/125\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 5.4922 - accuracy: 0.3318 - val_loss: 5.6823 - val_accuracy: 0.3467\n",
            "Epoch 47/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.4802 - accuracy: 0.3318 - val_loss: 5.6733 - val_accuracy: 0.3467\n",
            "Epoch 48/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.4687 - accuracy: 0.3318 - val_loss: 5.6656 - val_accuracy: 0.3467\n",
            "Epoch 49/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.4580 - accuracy: 0.3318 - val_loss: 5.6586 - val_accuracy: 0.3467\n",
            "Epoch 50/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.4486 - accuracy: 0.3318 - val_loss: 5.6518 - val_accuracy: 0.3467\n",
            "Epoch 51/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.4398 - accuracy: 0.3318 - val_loss: 5.6453 - val_accuracy: 0.3467\n",
            "Epoch 52/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.4314 - accuracy: 0.3318 - val_loss: 5.6390 - val_accuracy: 0.3467\n",
            "Epoch 53/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.4231 - accuracy: 0.3318 - val_loss: 5.6327 - val_accuracy: 0.3467\n",
            "Epoch 54/125\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 5.4152 - accuracy: 0.3318 - val_loss: 5.6269 - val_accuracy: 0.3467\n",
            "Epoch 55/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.4070 - accuracy: 0.3318 - val_loss: 5.6215 - val_accuracy: 0.3467\n",
            "Epoch 56/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3985 - accuracy: 0.3318 - val_loss: 5.6161 - val_accuracy: 0.3467\n",
            "Epoch 57/125\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 5.3907 - accuracy: 0.3318 - val_loss: 5.6107 - val_accuracy: 0.3467\n",
            "Epoch 58/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.3826 - accuracy: 0.3318 - val_loss: 5.6055 - val_accuracy: 0.3467\n",
            "Epoch 59/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3750 - accuracy: 0.3318 - val_loss: 5.6006 - val_accuracy: 0.3467\n",
            "Epoch 60/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3682 - accuracy: 0.3318 - val_loss: 5.5966 - val_accuracy: 0.3467\n",
            "Epoch 61/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3613 - accuracy: 0.3318 - val_loss: 5.5932 - val_accuracy: 0.3467\n",
            "Epoch 62/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.3550 - accuracy: 0.3318 - val_loss: 5.5898 - val_accuracy: 0.3467\n",
            "Epoch 63/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3504 - accuracy: 0.3318 - val_loss: 5.5879 - val_accuracy: 0.3467\n",
            "Epoch 64/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3481 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 65/125\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 66/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 67/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 68/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 69/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 70/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 71/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 72/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 73/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 74/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 75/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 76/125\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 77/125\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 78/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 79/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 80/125\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 81/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 82/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 83/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 84/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 85/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 86/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 87/125\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 88/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 89/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 90/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 91/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 92/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 93/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 94/125\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 95/125\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 96/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 97/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 98/125\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 99/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 100/125\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 101/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 102/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 103/125\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 104/125\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 105/125\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 5.3477 - accuracy: 0.3318 - val_loss: 5.5876 - val_accuracy: 0.3467\n",
            "Epoch 106/125\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 5.9192 - accuracy: 0.3672"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-8e3f60e40caf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### START CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m###### END CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-0bcb75e1910c>\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(X_train, y_train, X_test, y_test, n_batch)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m125\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1454\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1456\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1457\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1750\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 696\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    719\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 721\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3408\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3409\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 3410\u001b[0;31m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[1;32m   3411\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3412\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "### START CODE HERE ### \n",
        "batch_size = 128\n",
        "history = fit_model(X_train, y_train, X_test, y_test, batch_size)\n",
        "###### END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e9a46f6-a1ce-4922-b48f-3c6f54ae4515",
      "metadata": {
        "tags": [],
        "id": "7e9a46f6-a1ce-4922-b48f-3c6f54ae4515"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss vs. epochs, batch=' +str(batch_size))\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0c037e6-a554-454d-8d87-e009aefd826c",
      "metadata": {
        "id": "c0c037e6-a554-454d-8d87-e009aefd826c"
      },
      "source": [
        "##### Size =  Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f067cc9d-4c8e-434d-970e-5395914df5f1",
      "metadata": {
        "id": "f067cc9d-4c8e-434d-970e-5395914df5f1"
      },
      "source": [
        "10. **Retrain for length of data batch size**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6bcbb54-5017-4030-97a8-8a70bf2204ce",
      "metadata": {
        "id": "c6bcbb54-5017-4030-97a8-8a70bf2204ce"
      },
      "outputs": [],
      "source": [
        "### START CODE HERE ### \n",
        "batch_size = len(X_train)\n",
        "history = fit_model(X_train, y_train, X_test, y_test, batch_size)\n",
        "###### END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eca79f36-f9b9-444d-950b-5c3d55dfc307",
      "metadata": {
        "tags": [],
        "id": "eca79f36-f9b9-444d-950b-5c3d55dfc307"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss vs. epochs, batch=' +str(batch_size))\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d58d23e3-89c6-4596-80d3-33b98d895eb1",
      "metadata": {
        "id": "d58d23e3-89c6-4596-80d3-33b98d895eb1"
      },
      "source": [
        "10. **What effect does changing batch size have on learning in terms of convergence and fluctuations?**\n",
        "\n",
        "**Answer:** for bigger batch convergence becomes faster and less fluctuations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac0b0cdb-78c2-4239-bbb9-4bea511b52b1",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "ac0b0cdb-78c2-4239-bbb9-4bea511b52b1"
      },
      "source": [
        "#### Learning Rate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7be280d-068a-4695-b716-c1ef97d4d6f4",
      "metadata": {
        "id": "c7be280d-068a-4695-b716-c1ef97d4d6f4"
      },
      "source": [
        "batch size 64"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2970cd51-b911-455a-b6c3-17f477415759",
      "metadata": {
        "id": "2970cd51-b911-455a-b6c3-17f477415759"
      },
      "source": [
        "- **Use same code for build_model above, add an argument learning rate to change learning rate of optmizer**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64"
      ],
      "metadata": {
        "id": "nq9-aBfIBz4Y"
      },
      "id": "nq9-aBfIBz4Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "939ebb69-e520-4d68-9fa7-ce00f0257629",
      "metadata": {
        "id": "939ebb69-e520-4d68-9fa7-ce00f0257629"
      },
      "outputs": [],
      "source": [
        "def build_model(lr):\n",
        "    \n",
        "    ##### YOUR CODE HERE\n",
        "     # define model\n",
        "    model = tf.keras.models.Sequential([\n",
        "                                  tf.keras.layers.Dense(50, activation=tf.nn.relu,  kernel_initializer  = tf.keras.initializers.HeUniform()),\n",
        "                                  tf.keras.layers.Dense(3)])\n",
        "    # compile model\n",
        "    model.compile(optimizer = tf.optimizers.SGD(learning_rate = lr, momentum = 0.9),\n",
        "                  loss = 'categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72f1ebf6-5bcb-4e2b-bee7-3eb282fd88b1",
      "metadata": {
        "id": "72f1ebf6-5bcb-4e2b-bee7-3eb282fd88b1"
      },
      "source": [
        "##### LR =  0.00001"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "739eab80-d78f-4ca3-9992-42096088cf7a",
      "metadata": {
        "id": "739eab80-d78f-4ca3-9992-42096088cf7a"
      },
      "source": [
        "10. **Retrain for 0.00001 LR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb2ad280-97f1-4c16-9aad-d99c96780472",
      "metadata": {
        "tags": [],
        "id": "fb2ad280-97f1-4c16-9aad-d99c96780472"
      },
      "outputs": [],
      "source": [
        "### START CODE HERE ### ()\n",
        "# Print the model summary\n",
        "model = build_model(0.00001)\n",
        "history = model.fit(X_train, y_train,  batch_size = batch_size, epochs=125, validation_split = 0.15)\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f5e459c-4f1e-4bf3-88d7-3a7af2f789eb",
      "metadata": {
        "id": "6f5e459c-4f1e-4bf3-88d7-3a7af2f789eb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss vs. epochs, batch=' +str(batch_size))\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "467481cd-d773-479b-837b-94b0cd4c056a",
      "metadata": {
        "id": "467481cd-d773-479b-837b-94b0cd4c056a"
      },
      "source": [
        "##### LR =  0.001"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd885be3-5ac4-4bad-80eb-7a9e1850a3e5",
      "metadata": {
        "id": "bd885be3-5ac4-4bad-80eb-7a9e1850a3e5"
      },
      "source": [
        "10. **Retrain for 0.001 LR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afa0d071-55ed-42e5-bd40-ef410c33128f",
      "metadata": {
        "tags": [],
        "id": "afa0d071-55ed-42e5-bd40-ef410c33128f"
      },
      "outputs": [],
      "source": [
        "### START CODE HERE ### ()\n",
        "model = build_model(0.00001)\n",
        "history = model.fit(X_train, y_train,  batch_size = batch_size, epochs=125, validation_split = 0.15)\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53bf0abf-a145-4081-aa0b-e4ffe73c9357",
      "metadata": {
        "id": "53bf0abf-a145-4081-aa0b-e4ffe73c9357"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss vs. epochs, batch=' +str(batch_size))\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c476d8f-d9d5-49e9-bcb1-c47f3505d456",
      "metadata": {
        "id": "9c476d8f-d9d5-49e9-bcb1-c47f3505d456"
      },
      "source": [
        "##### LR =  0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5538b4df-7c6b-4d4d-9cbd-e7b14e57a8d6",
      "metadata": {
        "id": "5538b4df-7c6b-4d4d-9cbd-e7b14e57a8d6"
      },
      "source": [
        "10. **Retrain for 0.1 LR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c320fde-e42b-4d0a-941c-86b2c5817c66",
      "metadata": {
        "tags": [],
        "id": "2c320fde-e42b-4d0a-941c-86b2c5817c66"
      },
      "outputs": [],
      "source": [
        "### START CODE HERE ### ()\n",
        "model = build_model(0.1)\n",
        "history = model.fit(X_train, y_train,  batch_size = batch_size, epochs=125, validation_split = 0.15)\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abadecd9-9a79-45c0-8540-bf16d8b4bc27",
      "metadata": {
        "id": "abadecd9-9a79-45c0-8540-bf16d8b4bc27"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss vs. epochs, batch=' +str(batch_size))\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c665798-8db4-4b7f-a242-b34f3d0d317d",
      "metadata": {
        "id": "1c665798-8db4-4b7f-a242-b34f3d0d317d"
      },
      "source": [
        "10. **What effect does changing learning rate have on learning?**\n",
        "\n",
        "**Answer:** the optimal value that loss function converge faster is 0.001, when it's bigger than the optimal value it diverges and when it's smaller it needs more epochs to converge"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}